{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1fESObdFU5Xd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import statistics \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UM3AxNE9VHvX"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:\\Transformer_thesis\\Dataset\\V_228.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtSHGDixElx2",
    "outputId": "efa62bf7-6fe7-4360-dbd9-1942920ea94e"
   },
   "outputs": [],
   "source": [
    "#!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tX-Y_xXkJbcy"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0M19phoPWEmB",
    "outputId": "f1d98579-1092-4f6f-a56d-3622035f7c07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12672, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HLoDEekNWKol"
   },
   "outputs": [],
   "source": [
    "#data=df.iloc[:,:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j3gHHguLQCHw"
   },
   "outputs": [],
   "source": [
    "data=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rbooeerj7iEb",
    "outputId": "63818370-6425-45c2-9a3d-2e8bcd1c7533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12672, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_NCRjQI2WXSL"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "\n",
    "   test_size=1440\n",
    "   validation_size=1440\n",
    "   train_data=data[:-test_size - validation_size]\n",
    "\n",
    "   validation_data=data[-test_size - validation_size:-test_size]\n",
    "   test_data=data[-test_size:]\n",
    "   return train_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QAgegxvmWZmV"
   },
   "outputs": [],
   "source": [
    "def create_train_sequences(data,window_size,forecast_horizon):\n",
    "  #X=[]\n",
    "  #y=[]\n",
    "  X_shape=[(len(data)-window_size-forecast_horizon + 1),window_size]\n",
    "\n",
    "  y_shape=[(len(data)-window_size-forecast_horizon + 1),forecast_horizon]\n",
    "  X=np.zeros(X_shape)\n",
    "  y=np.zeros(y_shape)\n",
    "  for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "        _x = data[i:(i+window_size)]\n",
    "        #_y = data[i+window_size]\n",
    "        _y=data[i + window_size:i + window_size + forecast_horizon]\n",
    "        X[i,:]=_x\n",
    "        y[i,:]=_y\n",
    "\n",
    "\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VpJ6naogo_w4"
   },
   "outputs": [],
   "source": [
    "def create_test_sequences(data, window_size, forecast_horizon):\n",
    "\n",
    "    num_samples = len(data) // (window_size + forecast_horizon)\n",
    "    X_shape = (num_samples, window_size)\n",
    "    y_shape = (num_samples, forecast_horizon)\n",
    "    X = np.zeros(X_shape)\n",
    "    y = np.zeros(y_shape)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        start_index = i * (window_size + forecast_horizon)\n",
    "        end_index_x = start_index + window_size\n",
    "        end_index_y = end_index_x + forecast_horizon\n",
    "\n",
    "        _x = data[start_index:end_index_x]\n",
    "        _y = data[end_index_x:end_index_y]\n",
    "\n",
    "        X[i, :] = _x\n",
    "        y[i, :] = _y\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window=120\n",
    "\n",
    "def create_attention_seq(data,window_size,forecast_horizon,context_window):\n",
    "  X_attention=[]\n",
    "  end_index=0\n",
    "  for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "      if end_index < context_window:\n",
    "         _x=data[0:window_size+i]\n",
    "         end_index=window_size+i\n",
    "         zeros_to_add=[0]*(context_window - len(_x))\n",
    "         _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
    "      else:\n",
    "         _x=data[window_size+i-context_window-1:window_size+i-1]\n",
    "      X_attention.append(_x)\n",
    "  return X_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_test_sequences(data, window_size, forecast_horizon,context_window):\n",
    "   \n",
    "    X_attention=np.zeros((len(data),context_window))\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        \n",
    "        if(i<=int(context_window/sequence_length - 2)):       \n",
    "            subset_x=data[0:i+1]\n",
    "            X_attention[i]=np.concatenate ((np.zeros( sequence_length*((int(context_window/sequence_length)) - (i+1)) ), subset_x.reshape(-1)))   \n",
    "        else:\n",
    "            \n",
    "            start_index=int(i-((context_window/sequence_length)-1))\n",
    "            X_attention[i]=data[start_index:i+1].reshape(-1) \n",
    "     \n",
    "    return X_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "PNH0JaIM_bjS",
    "outputId": "f30d7837-6683-43bb-a9fe-e99bbb791c8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_test_sequences(data, window_size, forecast_horizon):\\n\\n    X_shape=[(len(data)-window_size- forecast_horizon + 1),window_size]\\n    y_shape=[(len(data)-window_size- forecast_horizon + 1),forecast_horizon]\\n    X=np.zeros(X_shape)\\n    y=np.zeros(y_shape)\\n    step_size = window_size + forecast_horizon\\n\\n    for i in range(0, len(data) - window_size - forecast_horizon + 1, step_size):\\n        _x = data[i:(i + window_size)]\\n        _y = data[i + window_size:i + window_size + forecast_horizon]\\n        X[i,:]=_x\\n        y[i,:]=_y\\n\\n    return X, y\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def create_test_sequences(data, window_size, forecast_horizon):\n",
    "\n",
    "    X_shape=[(len(data)-window_size- forecast_horizon + 1),window_size]\n",
    "    y_shape=[(len(data)-window_size- forecast_horizon + 1),forecast_horizon]\n",
    "    X=np.zeros(X_shape)\n",
    "    y=np.zeros(y_shape)\n",
    "    step_size = window_size + forecast_horizon\n",
    "\n",
    "    for i in range(0, len(data) - window_size - forecast_horizon + 1, step_size):\n",
    "        _x = data[i:(i + window_size)]\n",
    "        _y = data[i + window_size:i + window_size + forecast_horizon]\n",
    "        X[i,:]=_x\n",
    "        y[i,:]=_y\n",
    "\n",
    "    return X, y\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jiPBuOe5Wcff"
   },
   "outputs": [],
   "source": [
    "#sc=MinMaxScaler()\n",
    "#df_scaled=sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-xj0RcSHWegX"
   },
   "outputs": [],
   "source": [
    "#df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KTJcvInWWlYN"
   },
   "outputs": [],
   "source": [
    "sequence_length=12\n",
    "horizon=9\n",
    "batch_size=32\n",
    "input_size=1\n",
    "hidden_size=64\n",
    "output_size=1\n",
    "ff_hiddensize=64\n",
    "mask_flag=None\n",
    "attn_head=8\n",
    "start_dec_token_len=6\n",
    "test_size=1440\n",
    "validation_size=1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hsM8griF4xTg",
    "outputId": "9500fd6d-1587-4a3a-a62c-fda7b71feead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        71.1\n",
       "1        68.1\n",
       "2        68.0\n",
       "3        68.3\n",
       "4        68.9\n",
       "         ... \n",
       "12667    70.3\n",
       "12668    69.9\n",
       "12669    68.9\n",
       "12670    69.2\n",
       "12671    68.6\n",
       "Name: 0, Length: 12672, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9zbB2tpXWnlZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[0:window_size+i]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:13: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[window_size+i-context_window-1:window_size+i-1]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[0:window_size+i]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:13: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[window_size+i-context_window-1:window_size+i-1]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[0:window_size+i]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:13: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[window_size+i-context_window-1:window_size+i-1]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[0:window_size+i]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:13: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[window_size+i-context_window-1:window_size+i-1]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[0:window_size+i]\n",
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_8912\\1732260069.py:13: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  _x=data[window_size+i-context_window-1:window_size+i-1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_seq_x=np.zeros([df.shape[1], (len(df)-validation_size-test_size-sequence_length-horizon+1) , sequence_length ])\n",
    "train_seq_y=np.zeros([df.shape[1], (len(df)-validation_size-test_size-sequence_length-horizon+1) , horizon])\n",
    "valid_seq_x=np.zeros([df.shape[1], validation_size-sequence_length-horizon+1  , sequence_length ])\n",
    "valid_seq_y=np.zeros([df.shape[1], validation_size-sequence_length-horizon+1 , horizon ])\n",
    "test_seq_x=np.zeros([df.shape[1], test_size // (sequence_length + horizon), sequence_length ])\n",
    "test_seq_y=np.zeros([df.shape[1],  test_size // (sequence_length + horizon) , horizon])\n",
    "\n",
    "train_attention_x=np.zeros([df.shape[1], ((len(df)-validation_size-test_size-sequence_length-horizon+1)), context_window])\n",
    "valid_attention_x=np.zeros([df.shape[1],  validation_size-sequence_length-horizon+1, context_window])\n",
    "test_attention_x=np.zeros([df.shape[1], test_size // (sequence_length + horizon)  , context_window])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(df.shape[1]):\n",
    "  train_data,validation_data,test_data = train_test_split(df.iloc[:,i])\n",
    "  #print(train_data.shape)\n",
    "  #break\n",
    "\n",
    "  scaler.fit(train_data.values.reshape(-1, 1))\n",
    "  train_data_scaled = scaler.transform(train_data.values.reshape(-1, 1))\n",
    "\n",
    "  scaler.fit(validation_data.values.reshape(-1, 1))\n",
    "  validation_data_scaled = scaler.transform(validation_data.values.reshape(-1, 1))\n",
    "\n",
    "  scaler.fit(test_data.values.reshape(-1, 1))\n",
    "  test_data_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "  train_x,train_y=create_train_sequences(train_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "  #train_x,train_y=create_train_sequences(train_data,sequence_length,horizon)\n",
    "  \n",
    "\n",
    "  train_seq_x[i,:,:]=train_x\n",
    "  train_seq_y[i,:,:]=train_y\n",
    "  #train_seq_x.append(train_x)\n",
    "  #train_seq_y.append(train_y)\n",
    "\n",
    "  valid_x,valid_y=create_train_sequences(validation_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "  #valid_x,valid_y=create_train_sequences(validation_data,sequence_length,horizon)\n",
    "  valid_seq_x[i,:,:]=valid_x\n",
    "  valid_seq_y[i,:,:]=valid_y\n",
    "  #valid_seq_x.append(valid_x)\n",
    "  #valid_seq_y.append(valid_y)\n",
    "\n",
    "  test_x,test_y=create_test_sequences(test_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "\n",
    "  #test_x,test_y=create_test_sequences(test_data,sequence_length,horizon)\n",
    "  test_seq_x[i,:,:]=test_x\n",
    "  test_seq_y[i,:,:]=test_y\n",
    "  #test_seq_x.append(test_x)\n",
    "  #test_seq_y.append(test_y)\n",
    "  \n",
    "  train_attention_x[i,:,:]=create_attention_seq(train_data,sequence_length, horizon,context_window)\n",
    "  valid_attention_x[i,:,:]=create_attention_seq(validation_data,sequence_length, horizon,context_window)\n",
    "  test_attention_x[i,:,:]=create_attention_test_sequences(test_x,sequence_length, horizon,context_window)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3uSzaKpCOXmo"
   },
   "outputs": [],
   "source": [
    "X_train=torch.tensor(train_seq_x,dtype=torch.float32)\n",
    "y_train=torch.tensor(train_seq_y,dtype=torch.float32)\n",
    "X_valid=torch.tensor(valid_seq_x,dtype=torch.float32)\n",
    "y_valid=torch.tensor(valid_seq_y,dtype=torch.float32)\n",
    "X_test=torch.tensor(test_seq_x,dtype=torch.float32)\n",
    "y_test=torch.tensor(test_seq_y,dtype=torch.float32)\n",
    "\n",
    "X_train_attention=torch.tensor(train_attention_x,dtype=torch.float32)\n",
    "X_valid_attention=torch.tensor(valid_attention_x,dtype=torch.float32)\n",
    "X_test_attention=torch.tensor(test_attention_x,dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.9, 69.4, 68.4, 70.1, 70.3, 66.2, 66. , 67.4, 64. , 66.3, 66. ,\n",
       "       70.3, 69.2, 69.4, 71.5, 68.3, 70. , 64.9, 65.4, 64.6, 66.1, 65.8,\n",
       "       65.9, 67.1, 70.7, 70.6, 68.7, 69.1, 71.2, 71. , 73.4, 73.2, 72.5,\n",
       "       72.8, 72.4, 73.9, 73.7, 75. , 73.2, 76.3, 77.7, 72.7, 69.3, 68.1,\n",
       "       66.2, 65.4, 64.5, 62.8, 57.8, 50. , 48.1, 48.2, 44. , 41.2, 40.8,\n",
       "       46.6, 42.9, 37.7, 29.5, 26. , 24. , 23.5, 22.7, 22.2, 20.3, 14.9,\n",
       "       16.5, 24.2, 23.8, 24.4, 22.7, 24.8, 24. , 22.6, 23.1, 21.4, 20.9,\n",
       "       22.9, 23.9, 24.1, 23. , 22.1, 21.7, 23.7, 22.9, 22.3, 21.8, 21.3,\n",
       "       20.3, 20.7, 21.3, 20.6, 19.7, 21.8, 26.4, 25.8, 27.5, 28.5, 32.2,\n",
       "       39.3, 49.5, 56.3, 59.6, 59.6, 60.2, 60.3, 60.4, 60.4, 61.5, 62.6,\n",
       "       64.2, 64.2, 63.5, 62.8, 62.8, 60.6, 60.5, 61.1, 62.9, 62.4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention_x[0,140,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5ZPoQjXCDvz",
    "outputId": "52ada406-4df2-4da9-87e5-9549fd3bec0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9772, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "aS7NfdeAwOqZ",
    "outputId": "f4386eea-b4f4-4bfc-dcf5-6cd3b38f1442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_test=X_test.unsqueeze(-1)\\nX_test=X_test.view(-1,X_test.size(2),X_test.size(3))\\n\\ny_test=y_test.unsqueeze(-1)\\ny_test=y_test.view(-1,y_test.size(2),y_test.size(3))\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.unsqueeze(-1)\n",
    "X_train=X_train.view(-1,X_train.size(2),X_train.size(3))\n",
    "\n",
    "y_train=y_train.unsqueeze(-1)\n",
    "y_train=y_train.view(-1,y_train.size(2),y_train.size(3))\n",
    "\n",
    "X_valid=X_valid.unsqueeze(-1)\n",
    "X_valid=X_valid.view(-1,X_valid.size(2),X_valid.size(3))\n",
    "\n",
    "y_valid=y_valid.unsqueeze(-1)\n",
    "y_valid=y_valid.view(-1,y_valid.size(2),y_valid.size(3))\n",
    "\n",
    "X_test=X_test.unsqueeze(-1)\n",
    "y_test=y_test.unsqueeze(-1)\n",
    "\n",
    "\n",
    "X_train_attention=X_train_attention.unsqueeze(-1)\n",
    "X_train_attention=X_train_attention.view(-1,X_train_attention.size(-2),X_train_attention.size(3))\n",
    "\n",
    "X_valid_attention=X_valid_attention.unsqueeze(-1)\n",
    "X_valid_attention=X_valid_attention.view(-1,X_valid_attention.size(-2),X_valid_attention.size(3))\n",
    "\n",
    "X_test_attention=X_test_attention.unsqueeze(-1)\n",
    "\n",
    "\"\"\"\n",
    "X_test=X_test.unsqueeze(-1)\n",
    "X_test=X_test.view(-1,X_test.size(2),X_test.size(3))\n",
    "\n",
    "y_test=y_test.unsqueeze(-1)\n",
    "y_test=y_test.view(-1,y_test.size(2),y_test.size(3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lVjZ-zrcLewd"
   },
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "  def __init__(self,X,y):\n",
    "    self.X=X\n",
    "    self.y=y\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDataset(Dataset):\n",
    "  def __init__(self,X):\n",
    "    self.X=X\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mPMbcoQ1PGrm"
   },
   "outputs": [],
   "source": [
    "train_dataset=TimeseriesDataset(X_train,y_train)\n",
    "valid_dataset=TimeseriesDataset(X_valid,y_valid)\n",
    "test_dataset=TimeseriesDataset(X_test,y_test)\n",
    "\n",
    "train_attention_dataset=AttentionDataset(X_train_attention)\n",
    "valid_attention_dataset=AttentionDataset(X_valid_attention)\n",
    "test_attention_dataset=AttentionDataset(X_test_attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "xEsyYaYpPJWd"
   },
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size,drop_last=True)\n",
    "valid_loader=DataLoader(valid_dataset,batch_size,drop_last=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size,drop_last=True)\n",
    "\n",
    "train_attention_loader=DataLoader(train_attention_dataset,batch_size,drop_last=True)\n",
    "valid_attention_loader=DataLoader(valid_attention_dataset,batch_size,drop_last=True)\n",
    "test_attention_loader=DataLoader(test_attention_dataset,batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1BdJIZImOjLl"
   },
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size):\n",
    "      super().__init__()\n",
    "      self.input_size=input_size\n",
    "      self.hidden_size=hidden_size\n",
    "      self.conv1d=nn.Conv1d(in_channels=self.input_size,out_channels=self.hidden_size,padding=1,kernel_size=3,bias=False)\n",
    "  def forward(self,x):\n",
    "      embedded_inp=self.conv1d(x.permute(0,2,1))\n",
    "      return embedded_inp.transpose(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionalEncoder(nn.Module):\n",
    "    def __init__(self,head_dim,max_pos=12):\n",
    "        super(RelativePositionalEncoder,self).__init__()\n",
    "        self.max_pos=max_pos\n",
    "        self.head_dim=head_dim\n",
    "        self.pos_embed=nn.Parameter(torch.Tensor(max_pos * 2 + 1, emb_dim))\n",
    "    def forward(self,seq_len):\n",
    "        pos_range=torch.arange(seq_len)\n",
    "        relative_pos=pos_range[:,None]-pos_range[None,:]\n",
    "        rel_pos += self.max_len - 1  \n",
    "        return self.rel_pos_embed(rel_pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DnnOQkO7OmtX"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()* -(math.log(10000.0) / d_model)).exp()\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self,x):\n",
    "        return self.pe[:,:x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationAttentionLayer(nn.Module):\n",
    "  def __init__(self,attn_head,hidden_size):\n",
    "    super().__init__()\n",
    "    self.attn_head=attn_head\n",
    "    self.hidden_size=hidden_size\n",
    "    self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "    self.queries_emb=nn.Linear(hidden_size,hidden_size)\n",
    "    self.keys_emb=nn.Linear(hidden_size,hidden_size)\n",
    "    self.values_emb=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "  def forward(self,q,k,v,attention_mask,return_attention):\n",
    "    b,l,d=q.shape\n",
    "    b,s,d=k.shape\n",
    "\n",
    "    #Linear projection and creation of multiple heads\n",
    "    queries=self.queries_emb(q).view(b,l,self.attn_head,-1)\n",
    "    keys=self.keys_emb(k).view(b,s,self.attn_head,-1)\n",
    "    values=self.values_emb(v).view(b,s,self.attn_head,-1)\n",
    "\n",
    "    b,l,h,d=queries.shape\n",
    "    b,s,h,d=values.shape\n",
    "\n",
    "    if l > s:\n",
    "            zeros = torch.zeros_like(queries[:, :(l - s), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "    else:\n",
    "            values = values[:, :l, :, :]\n",
    "            keys = keys[:, :l, :, :]\n",
    "\n",
    "    top_k=4\n",
    "\n",
    "    q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "    k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "    \n",
    "    res = q_fft * torch.conj(k_fft)\n",
    "    \n",
    "    corr = torch.fft.irfft(res, n=l, dim=-1)\n",
    "    \n",
    "    mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "    top2_values, top2_indices = torch.topk(mean_value, 2, dim=1)\n",
    "    #print(f\"top2_indices:{top2_indices}\")\n",
    "    #max_value, max_index = torch.max(mean_value, dim=1)\n",
    "    #print(f\"max_index: {max_index}\")\n",
    "    \n",
    "    index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "    weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "\n",
    "    tmp_corr = torch.softmax(weights, dim=-1)\n",
    "\n",
    "    values=values.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    tmp_values = values\n",
    "    delays_agg = torch.zeros_like(values).float()\n",
    "\n",
    "    for i in range(top_k):\n",
    "        pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "        delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, h, d, l))\n",
    "    agg_seq=delays_agg.permute(0, 3, 1, 2).view(b,l,-1)\n",
    "    return agg_seq\n",
    "    #return agg_seq[:,:sequence_length+3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(seq_win,con_win):\n",
    "    #seq_win_norm=normalize(seq_win)\n",
    "    #con_win_norm=normalize(con_win)\n",
    "    corr=np.correlate(con_win[i].reshape(-1),seq_win[i].reshape(-1),mode=\"valid\")\n",
    "    return corr\n",
    "def get_correlation_seq(seq_win,con_win):\n",
    "    batch_size=seq_win.shape[0]\n",
    "    correlation_batch_index=np.zeros(batch_size)\n",
    "    correlation_batch_val=np.zeros(batch_size)\n",
    "    correlation_seq=torch.zeros((batch_size,sequence_length,1))\n",
    "    for i in range(batch_size):\n",
    "        seq_win_batch=seq_win[i]\n",
    "        context_win_batch=con_win[i]  \n",
    "        correlation=[]\n",
    "        for j in range(context_window-sequence_length):\n",
    "            sequence_window=seq_win_batch \n",
    "            context_window_data=context_win_batch[j:j+12,:]         \n",
    "            corr=autocorrelation(sequence_window,context_window_data) \n",
    "            correlation.append(corr)\n",
    "        max_correlation=max(correlation)\n",
    "        max_correlation_index=np.argmax(correlation)\n",
    "        \n",
    "        l_a,_=con_win[i,max_correlation_index:max_correlation_index+12,:].shape\n",
    "        if l_a < sequence_length:  \n",
    "            prev_index=sequence_length-l_a  \n",
    "            correlation_seq[i]=con_win[i,max_correlation_index-prev_index:,:]\n",
    "        else:\n",
    "            correlation_seq[i]=con_win[i,max_correlation_index:max_correlation_index+12,:] \n",
    "    return correlation_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Vc7rG2iSOqlz"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "  def __init__(self,attn_head,hidden_size):\n",
    "    super().__init__()\n",
    "\n",
    "    self.attn_head=attn_head\n",
    "    self.hidden_size=hidden_size\n",
    "    self.dropout = nn.Dropout(0.01)\n",
    "    self.linear=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "    self.queries=nn.Linear(hidden_size,hidden_size)\n",
    "    self.keys=nn.Linear(hidden_size,hidden_size)\n",
    "    self.values=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "  def forward(self, queries,keys,values,attention_mask,return_attention=False):\n",
    "    b,l,d=queries.shape\n",
    "    b,s,d=keys.shape\n",
    "    \n",
    "    #Linear projection and creation of multiple heads\n",
    "    queries=self.queries(queries).view(b,l,self.attn_head,-1)\n",
    "    keys=self.keys(keys).view(b,s,self.attn_head,-1)\n",
    "    values=self.values(values).view(b,s,self.attn_head,-1)\n",
    "\n",
    "    b,l,h,d=queries.shape\n",
    "    b,s,h,d=values.shape\n",
    "\n",
    "    #Calculate attention score\n",
    "    attention_score=torch.einsum(\"blhd,bshd->bhls\",queries,keys)\n",
    "    #print(f\"attention_score00:{attention_score[0][0]} attention_score01:{attention_score[0][1]} attention_score02:{attention_score[0][2]}\")\n",
    "    if attention_mask == True:\n",
    "       mask_shape = [b,1,l,l]\n",
    "       mask=torch.triu(torch.ones(mask_shape,dtype=torch.bool),diagonal=1)\n",
    "       attention_score.masked_fill_(mask,-np.inf)\n",
    "    \n",
    "    #print(f\"attention_score:{attention_score[0][0]} attention_score:{attention_score[0][1]} attention_score:{attention_score[0][2]}\")\n",
    "     \n",
    "    \n",
    "    attention_score_softmax=self.dropout(torch.softmax(attention_score/sqrt(d),dim=-1))\n",
    "    \n",
    "    #print(f\"attention_score_softmax 00: {attention_score_softmax[0][0]} attention_score_softmax01 {attention_score_softmax[0][1]} attention_score_softmax02{attention_score_softmax[0][2]}\")\n",
    "    #print(f\"attention_score_softmax: {attention_score_softmax[0][0]}\")\n",
    "    \n",
    "    final_value=torch.einsum(\"bhls,bshd->blhd\",attention_score_softmax,values)\n",
    "    #print(f\"final_value: {final_value.shape}\")\n",
    "    weighted_attn_val=self.linear(final_value.contiguous().view(b,l,-1))\n",
    "        \n",
    "    if return_attention==True:\n",
    "        return weighted_attn_val,attention_score_softmax\n",
    "    else:\n",
    "        #return weighted_attn_val\n",
    "        #If using context_window for attention \n",
    "        #print(f\"weighted_attn_val:{weighted_attn_val[:,-15:,:].shape}\")\n",
    "        #print(f\"weighted_attn_val shape:{weighted_attn_val.shape}\")\n",
    "        return weighted_attn_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9ixwqm1oOtXQ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,attention,hidden_size,output_size,ff_hiddensize,sequence_length):\n",
    "    super().__init__()\n",
    "    self.attention=attention\n",
    "    self.conv1=nn.Conv1d(in_channels=hidden_size,out_channels=ff_hiddensize,kernel_size=1)\n",
    "    self.conv2=nn.Conv1d(in_channels=ff_hiddensize,out_channels=hidden_size,kernel_size=1)\n",
    "    self.linear=nn.Linear(ff_hiddensize,hidden_size)\n",
    "    #self.norm1=nn.LayerNorm(normalized_shape=(sequence_length,hidden_size))\n",
    "    self.norm1=nn.LayerNorm(hidden_size)\n",
    "    self.activation=F.gelu\n",
    "    self.dropout=nn.Dropout(0.01)\n",
    "  \"\"\"\n",
    "  def forward(self,x):\n",
    "    #self.norm2=nn.LayerNorm(hidden_size)\n",
    "    ##attention_x=self.attention(x,x,x,attention_mask=False)\n",
    "    #add and normalize\n",
    "    ##new_x = x + self.dropout(attention_x)\n",
    "    ##res_x=x=self.norm1(new_x)\n",
    "    ##Feed forward NN:\n",
    "    out=self.conv1(x.permute(0,2,1))\n",
    "    out=self.activation(out)\n",
    "    out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "    ##Add and normalize:\n",
    "    ##new_out=out+res_x\n",
    "    ##norm_out=self.norm1(new_out)\n",
    "    norm_out=self.norm1(out)\n",
    "    \n",
    "    return norm_out\n",
    "  \"\"\"\n",
    "  \n",
    "  #def forward(self,x):\n",
    "  def forward(self,x,x_context):\n",
    "    #self.norm2=nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    #Without context_window\n",
    "    ##attention_x=self.attention(x,x,x,attention_mask=False,return_attention=False)\n",
    "    \n",
    "    #With context_window\n",
    "    attention_x=self.attention(x,x_context,x_context,attention_mask=False,return_attention=False)\n",
    "    \n",
    "    #add and normalize\n",
    "    new_x = x + attention_x\n",
    "    res_x=x=self.norm1(new_x)\n",
    "    ##Feed forward NN:\n",
    "    out=self.conv1(res_x.permute(0,2,1))\n",
    "    out=self.dropout(self.activation(out)) \n",
    "    out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "    ##Add and normalize:\n",
    "    new_out=out+res_x\n",
    "    norm_out=self.norm1(new_out)\n",
    "    return norm_out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "defFCswFOwsC"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,attention,hidden_size,output_size,ff_hiddensize,sequence_length):\n",
    "    super().__init__()\n",
    "    self.attention=attention\n",
    "    #print(f\"decoder output size: {output_size}\")\n",
    "    self.conv1=nn.Conv1d(in_channels=hidden_size,out_channels=ff_hiddensize,kernel_size=1)\n",
    "    self.conv2=nn.Conv1d(in_channels=ff_hiddensize,out_channels=hidden_size,kernel_size=1)\n",
    "    self.linear1=nn.Linear(hidden_size,ff_hiddensize)\n",
    "    self.linear2=nn.Linear(ff_hiddensize,hidden_size)\n",
    "    self.linear3=nn.Linear(hidden_size,output_size)\n",
    "    self.dropout=nn.Dropout(0.01)\n",
    "    self.norm1=nn.LayerNorm(hidden_size)\n",
    "    self.norm2=nn.LayerNorm(hidden_size)\n",
    "    self.norm3=nn.LayerNorm(hidden_size)\n",
    "    self.activation=F.relu\n",
    "    \n",
    "  \n",
    "  #With attention\n",
    "  def forward(self,dec_inp,enc_out):\n",
    "    #calculate self attention by passing dec_inp as Queries,keys and values\n",
    "    self_attn=self.attention(dec_inp,dec_inp,dec_inp,attention_mask=True,return_attention=False)\n",
    "    #print(f\"self_attn type:{type(self_attn)} dec_inp type:{type(dec_inp)} \")\n",
    "    #add residual connection and normalize\n",
    "    residual_add=self_attn+dec_inp\n",
    "    new_dec_x=self.norm1(residual_add)\n",
    "\n",
    "    # encoder-decoder attention. Pass key and value as encoder output and queries are output of 1st attention\n",
    "    enc_dec_atten=self.attention(new_dec_x,enc_out,enc_out,attention_mask=False,return_attention=False)\n",
    "    ## add and normalize\n",
    "    \n",
    "    new_x=enc_dec_atten+self_attn\n",
    "    norm_x=self.norm2(new_x)\n",
    "\n",
    "    #FFN\n",
    "    out=self.conv1(norm_x.permute(0,2,1))\n",
    "    out=self.dropout(self.activation(out))\n",
    "    out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "    #add and normalize\n",
    "    new_x=out+norm_x\n",
    "    out=self.norm3(new_x)\n",
    "\n",
    "    #Linear projection\n",
    "    pred=self.linear3(out)\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "  \"\"\" \n",
    "  #Without attention\n",
    "  def forward(self,dec_inp,enc_out):\n",
    "    #calculate self attention by passing dec_inp as Queries,keys and values\n",
    "    ##self_attn=self.attention(dec_inp,dec_inp,dec_inp,attention_mask=True)\n",
    "    #add residual connection and normalize\n",
    "    ##residual_add=self_attn+dec_inp\n",
    "    ##new_dec_x=self.norm1(residual_add)\n",
    "\n",
    "    # encoder-decoder attention. Pass key and value as encoder output and queries are output of 1st attention\n",
    "    ##enc_dec_atten=self.attention(new_dec_x,enc_out,enc_out,attention_mask=False)\n",
    "    ## add and normalize\n",
    "    ##new_x=enc_dec_atten+self_attn\n",
    "    ##norm_x=self.norm2(new_x)\n",
    "    \n",
    "    #FFN\n",
    "    out=self.conv1(enc_out.permute(0,2,1))\n",
    "    out=self.activation(out)\n",
    "    out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "    #add and normalize\n",
    "    ##new_x=out+norm_x\n",
    "    ##out=self.norm3(new_x)\n",
    "    out=self.norm3(out)\n",
    "\n",
    "    #Linear projection\n",
    "    pred=self.linear3(out)\n",
    "\n",
    "    return pred\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "jnI2WldAO0ci"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,output_size,ff_hiddensize,mask_flag,attn_head,sequence_length):\n",
    "      super().__init__()\n",
    "      self.input_size=input_size\n",
    "      self.hidden_size=hidden_size\n",
    "      self.output_size=output_size\n",
    "      self.ff_hidden_size=ff_hiddensize\n",
    "      self.mask_flag=mask_flag\n",
    "      self.attn_head=attn_head\n",
    "      self.sequence_length=sequence_length\n",
    "      \n",
    "      self.enc_embedding=InputEmbedding(self.input_size,self.hidden_size)\n",
    "      self.dec_embedding=InputEmbedding(self.input_size,self.hidden_size)\n",
    "      self.enc_positional_embedding=PositionalEmbedding(self.hidden_size)\n",
    "      self.dec_positional_embedding=PositionalEmbedding(self.hidden_size)\n",
    "      \n",
    "      self.linear=nn.Linear(hidden_size,output_size)\n",
    "      self.encoder=  Encoder( AttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length)\n",
    "      #self.encoders = nn.ModuleList([Encoder(AttentionLayer(self.attn_head, hidden_size), hidden_size, output_size, ff_hiddensize, sequence_length)\n",
    "                                        #for _ in range(2)])\n",
    "      self.decoder=Decoder( AttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length )\n",
    "      \n",
    "      ###Auto correlation attention  \n",
    "      #self.encoder=Encoder( CorrelationAttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length)  \n",
    "      #self.decoder=Decoder( CorrelationAttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length )  \n",
    "        \n",
    "      #self.decoders = nn.ModuleList([Decoder( AttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length )\n",
    "      #                                  for _ in range(2)])\n",
    "      self.dropout=nn.Dropout(0.01) \n",
    "   ##Without context_window\n",
    "  #def forward(self,x,y,training):\n",
    "   ##With context_window:\n",
    "  def forward(self,x,y,x_attn):\n",
    "\n",
    "      #dec inp:\n",
    "      #input is shifted right and concatenated with 1st time step embedding set as zero\n",
    "      #decoder_input = torch.cat([torch.zeros_like(y[:, :1, :]), y[:, :-1, :]], dim=1)\n",
    "      #print(f\"x shape: {x[:, -start_dec_token_len:, :].shape}, y shape: {y[:, -horizon:, :].shape}\")\n",
    "      #print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
    "      #decoder_input = torch.cat((x[:, -start_dec_token_len:, :], torch.zeros_like(y[:, -horizon:, :])), dim=1)\n",
    "      #decoder_input = torch.cat((x[:, :,-start_dec_token_len ,:], torch.zeros_like(y[:, :,-horizon:, :])), dim=1)\n",
    "      #print(f\"decoder_input shape: {decoder_input.shape}\")\n",
    "\n",
    "      #decoder_input=torch.zeros_like(y[:, -horizon:, :])\n",
    "        \n",
    "      decoder_input = torch.cat((x[:, -4:, :], torch.zeros_like(y[:, :, :])), dim=1)\n",
    "    \n",
    "      \"\"\"\n",
    "      if(training == True):\n",
    "        \n",
    "        decoder_input=torch.cat((X[:,-1:,:],y[:, :-1, :]),dim=1)\n",
    "      else:\n",
    "        \n",
    "        decoder_input=torch.zeros_like(y[:, -horizon:, :])\n",
    "      \"\"\"\n",
    "      #print(f\"x_attn:{x_attn}\")\n",
    "      corr_seq=get_correlation_seq(x,x_attn) \n",
    "      #encoder\n",
    "      inp_embed=self.enc_embedding(x)\n",
    "      pos_embed=self.enc_positional_embedding(x)\n",
    "      enc_out=inp_embed + pos_embed\n",
    "\n",
    "      ##With context_window\n",
    "      inp_embed=self.enc_embedding(corr_seq)\n",
    "      pos_embed=self.enc_positional_embedding(corr_seq)\n",
    "      attn_enc_out= inp_embed + pos_embed\n",
    "      ##End of With context_window\n",
    "        \n",
    "      #for encoder in self.encoders:\n",
    "    \n",
    "      ##Without context_window \n",
    "      #enc_out=self.encoder(enc_out)\n",
    "    \n",
    "      ##With context_window\n",
    "      enc_out=self.encoder(enc_out,attn_enc_out)\n",
    "      \n",
    "      #decoder\n",
    "      inp_embed=self.dec_embedding(decoder_input)\n",
    "      pos_embed=self.dec_positional_embedding(decoder_input)\n",
    "      dec_val= inp_embed + pos_embed\n",
    "      #print(f\"y passed to decoder shape: {y.shape}\")\n",
    "      \"\"\"\n",
    "      for decoder in self.decoders:\n",
    "          dec_val=decoder(dec_val,enc_out)\n",
    "      \"\"\"\n",
    "    \n",
    "      #pred=self.linear(dec_val)    \n",
    "      out=self.decoder(dec_val,enc_out)\n",
    "      \n",
    "      return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-KlFfL9wO3bN"
   },
   "outputs": [],
   "source": [
    "model=TransformerModel(input_size,hidden_size,output_size,ff_hiddensize,mask_flag,attn_head,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "PlgwBTAcO5NG"
   },
   "outputs": [],
   "source": [
    "loss_fun=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████                                                                                                            | 1/5 [13:07<52:28, 787.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:45.86104228440306 valid_loss:32.36109941307775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████                                                                                 | 2/5 [26:09<39:12, 784.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:38.77177779851078 valid_loss:32.78890797940854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 3/5 [39:50<26:42, 801.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 train_loss:37.076839935420224 valid_loss:30.94172530530265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4/5 [52:55<13:14, 794.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 train_loss:35.979323417026436 valid_loss:28.975511955999142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [1:01:29<00:00, 737.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 train_loss:35.09912681595213 valid_loss:29.17205421039961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "#With context window\n",
    "##\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        train_loss=[]\n",
    "        valid_total_loss=[]\n",
    "        model.train()\n",
    "        for (batch_idx, (X,y)),(batch_idx_2,(X_attn)) in zip(enumerate(train_loader), enumerate(train_attention_loader)):\n",
    "            \n",
    "            pred=model(X,y,X_attn)\n",
    "            \n",
    "            pred=pred[:,-horizon:,:]\n",
    "            optimizer.zero_grad()\n",
    "            loss=loss_fun(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "            batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "      \n",
    "            outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "            batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "            \n",
    "            tloss=loss_fun(outputs,batch_y)\n",
    "            train_loss.append(tloss.item())\n",
    "        train_loss = np.average(train_loss)    \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (batch_idx, (X,y)), (batch_idx_2,(X_attn)) in zip(enumerate(valid_loader), enumerate(valid_attention_loader)):\n",
    "              pred=model(X,y,X_attn)\n",
    "              pred=pred[:,-horizon:,:]\n",
    "            \n",
    "              outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "              batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "              outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "              batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "                \n",
    "                \n",
    "              valid_loss=loss_fun(outputs,batch_y) \n",
    "              valid_total_loss.append(valid_loss.item())\n",
    "                \n",
    "              valid_loss=loss_fun(outputs,batch_y)\n",
    "        valid_total_loss=np.average(valid_total_loss)\n",
    "        #if epoch%10==0:\n",
    "        #print(f\"epoch: {epoch} train loss:{loss} valid loss:{valid_loss} \")\n",
    "        print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "kuAyRTueO7LB",
    "outputId": "30ad38e4-32e8-4117-bb9e-6c5198c2d6fe",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in tqdm(range(epochs)):\\n        train_loss=[]\\n        valid_total_loss=[]\\n        model.train()\\n        for i, (X,y) in enumerate(train_loader):\\n            #print(f\"X:{X} y:{y}\")\\n            pred=model(X,y,training=True)\\n            \\n            #print(f\"pred shape: {pred.shape}, attention_val shape: {attention_val.shape}\")\\n            pred=pred[:,-horizon:,:]\\n            optimizer.zero_grad()\\n            loss=loss_fun(pred,y)\\n            loss.backward()\\n            optimizer.step()\\n            outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\\n            batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\\n\\n                # print(f\"outputs shape:{outputs.shape} type:{type(outputs)}\")\\n                # print(f\"batch_y shape: {batch_y.shape}\")\\n\\n            outputs = torch.tensor(outputs_inv.reshape(pred.shape))\\n            batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\\n            tloss=loss_fun(outputs,batch_y)\\n            train_loss.append(tloss.item())\\n            #if (i + 1) % 100 == 0:\\n                    #print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, tloss.item()))\\n        train_loss = np.average(train_loss)\\n        \\n        model.eval()\\n        \\n        with torch.no_grad():\\n          for batch_idx, (X,y) in enumerate(valid_loader):\\n              pred=model(X,y,training=True)\\n              pred=pred[:,-horizon:,:]\\n            \\n              outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\\n              batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\\n\\n                # print(f\"outputs shape:{outputs.shape} type:{type(outputs)}\")\\n                # print(f\"batch_y shape: {batch_y.shape}\")\\n\\n              outputs = torch.tensor(outputs_inv.reshape(pred.shape))\\n              batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\\n              #valid_loss=loss_fun(pred,y)\\n              valid_loss=loss_fun(outputs,batch_y) \\n              valid_total_loss.append(valid_loss.item())\\n        valid_total_loss=np.average(valid_total_loss)\\n        print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\")      \\n                \\n        #if epoch%10==0:\\n        #print(f\"epoch: {epoch} train loss:{tloss} valid loss:{valid_loss} \")\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "#Without Context window\n",
    "##\n",
    "\"\"\"\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        train_loss=[]\n",
    "        valid_total_loss=[]\n",
    "        model.train()\n",
    "        for i, (X,y) in enumerate(train_loader):\n",
    "            #print(f\"X:{X} y:{y}\")\n",
    "            pred=model(X,y,training=True)\n",
    "            \n",
    "            #print(f\"pred shape: {pred.shape}, attention_val shape: {attention_val.shape}\")\n",
    "            pred=pred[:,-horizon:,:]\n",
    "            optimizer.zero_grad()\n",
    "            loss=loss_fun(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "            batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                # print(f\"outputs shape:{outputs.shape} type:{type(outputs)}\")\n",
    "                # print(f\"batch_y shape: {batch_y.shape}\")\n",
    "\n",
    "            outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "            batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "            tloss=loss_fun(outputs,batch_y)\n",
    "            train_loss.append(tloss.item())\n",
    "            #if (i + 1) % 100 == 0:\n",
    "                    #print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, tloss.item()))\n",
    "        train_loss = np.average(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "          for batch_idx, (X,y) in enumerate(valid_loader):\n",
    "              pred=model(X,y,training=True)\n",
    "              pred=pred[:,-horizon:,:]\n",
    "            \n",
    "              outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "              batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                # print(f\"outputs shape:{outputs.shape} type:{type(outputs)}\")\n",
    "                # print(f\"batch_y shape: {batch_y.shape}\")\n",
    "\n",
    "              outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "              batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "              #valid_loss=loss_fun(pred,y)\n",
    "              valid_loss=loss_fun(outputs,batch_y) \n",
    "              valid_total_loss.append(valid_loss.item())\n",
    "        valid_total_loss=np.average(valid_total_loss)\n",
    "        print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\")      \n",
    "                \n",
    "        #if epoch%10==0:\n",
    "        #print(f\"epoch: {epoch} train loss:{tloss} valid loss:{valid_loss} \")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdCjLVZqbsye",
    "outputId": "c47a4f42-72fb-46f2-ec9d-3dce5a431aca"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "J8NvGxk0irH1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "plot_dir = 'D:\\Transformer_thesis\\Plots_test_correlation_dot_attention'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "tzuURam_SN5O"
   },
   "outputs": [],
   "source": [
    "output=[]\n",
    "ground_truth=[]\n",
    "pred_series=[]\n",
    "truth_series=[]\n",
    "loss=[]\n",
    "pred_total=[]\n",
    "y_total=[]\n",
    "enc_attention_map=[]\n",
    "dec_self_attention_map=[]\n",
    "dec_cross_attention_map=[]\n",
    "\n",
    "for i in range(X_test.size(0)):\n",
    "  curent_X_test=X_test[i,:,:,:]\n",
    "  current_y_test=y_test[i,:,:,:]\n",
    "  current_X_attention=X_test_attention[i,:,:,:]\n",
    "  pred=model(curent_X_test,current_y_test,current_X_attention)\n",
    "  \"\"\"\n",
    "  enc_attention_map.append(enc_attention)\n",
    "  dec_self_attention_map.append(dec_self_attention)\n",
    "  dec_cross_attention_map.append(dec_cross_attention)  \n",
    "  \"\"\"\n",
    "  #print(f\"attention_val shape: {attention_val.shape}\")\n",
    "  pred=pred[:,-horizon:,:]\n",
    "  pred=pred.reshape(-1,1).detach().numpy()\n",
    "  current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "  \n",
    "  pred_raw=scaler.inverse_transform(pred)\n",
    "  current_y_test_raw=scaler.inverse_transform(current_y_test)\n",
    "  loss.append(loss_fun(torch.tensor(pred_raw),torch.tensor(current_y_test_raw)))\n",
    "\n",
    "  #print(f\"pred: {pred}\")\n",
    "  #loss.append(loss_fun(torch.tensor(pred),torch.tensor(current_y_test)))\n",
    "\n",
    "\n",
    "  #print(current_y_test[:300])\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.plot(current_y_test, label='Ground Truth')\n",
    "  plt.plot(pred, label='Predicted')\n",
    "  plt.title(f'Time Series {i+1}: Ground Truth vs Predicted Values')\n",
    "  plt.xlabel('Time')\n",
    "  plt.ylabel('Value')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  #plt.show()\n",
    "  plt.savefig(os.path.join(plot_dir, f'Time_Series_{i+1}_plot.png'))\n",
    "  plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0eMqA3VhR8FJ",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(53.7491),\n",
       " tensor(53.3235),\n",
       " tensor(45.4637),\n",
       " tensor(60.8301),\n",
       " tensor(58.3371)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54.3407)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val=torch.stack(loss,dim=0)\n",
    "mean_loss=torch.mean(loss_val)\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "XAshzh2wSXSQ",
    "outputId": "f55c6b01-8fc8-462f-92cb-5aa1607832a9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAFzCAYAAADv+wfzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABAeElEQVR4nO3deXxV5bX/8c/KRICEhDEMAQIIIjMkIIMD1FpnrVXUVjT0atX2tnayvR28nb3119Fqba21LUGrKM7zDE4BJZFRZiGBMIUxAyHz8/sjBwsYIIHss885+/t+vfLKOfsMey12OFl59n7WY845RERERMR7cX4HICIiIhIUKrxEREREwkSFl4iIiEiYqPASERERCRMVXiIiIiJhosJLREREJEwS/A6gJbp16+aysrI83cf+/fvp2LGjp/uIZEHOP8i5Q7DzV+7BzB2CnX+Qc4fw5F9YWLjLOde9uceiovDKysqioKDA033Mnz+fqVOnerqPSBbk/IOcOwQ7f+U+1e8wfBPk/IOcO4QnfzMrPtpjOtUoIiIiEiYqvERERETCRIWXiIiISJhExTVeIiIiEl3q6uooKSmhurra71AOk5aWxqpVq9rkvZKTk8nMzCQxMbHFr1HhJSIiIm2upKSE1NRUsrKyMDO/w/lERUUFqampJ/0+zjl2795NSUkJAwYMaPHrdKpRRERE2lx1dTVdu3aNqKKrLZkZXbt2bfWIngovERER8USsFl0HnUh+KrxEREQkJqWkpPgdwqeo8BIREREJExVeIiIiEhjLli1j4sSJjBo1issvv5y9e/cCcPfddzNs2DBGjRrFNddcA8Bbb73FmDFjGDNmDGPHjqWiouKk969ZjSIiIuKpnz/3ESu3lrfpew7r3YmfXjK81a+7+eabuffeezn77LP5yU9+ws9//nPuuusu7rzzTjZu3Ei7du3Yt28fAL/73e+49957mTJlCpWVlSQnJ5903BrxEhGRQNmws5LyWud3GOKDsrIyysrKOPvsswHIzc3l7bffBmDUqFFce+21PPTQQyQkNI1LTZkyhe985zvcfffd7Nu375PtJ0MjXiIiEhilFdVc8Kd3qG9o5PntBUzP6cvUU7uTGK9xCC+dyMhUuL3wwgu8/fbbPPfcc9xxxx0sX76cH/zgB1x00UW8+OKLTJkyhVdeeYWhQ4ee1H5UeImISGA88v5mauobmdY3gQ837eXVlTvoltKOL4zrw/TsTAZnnHxjTYlcaWlppKen884773DmmWfy4IMPcvbZZ9PY2MjmzZuZNm0aZ5xxBnPmzKGyspLdu3czcuRIRo4cyaJFi1i9erUKLxERkZaorW/kofeLOXtId3IHVjHlzLOYv2Yncws28893N3L/2xsY3Ted6dmZXDK6N2ntW74MjESmqqoqMjMzP7n/ne98h/vuu4/vfve7VFVVMXDgQP71r3/R0NDAjBkzKCsrwznHrbfeSnp6Ov/7v//LvHnziIuLY/jw4VxwwQUnHZMKLxERCYSXVmxjZ0UNM6/Mgm0rSYyP49xhGZw7LINdlTU8vXgLjxeWcPvTK/jl8ys5b3hPrsrpy+RBXYmLi+1GoLGqsbHxU9sqKipYuHDhp7a/++67n9p2zz33tHlMKrxERCQQZuUXMaBbR84e3J23tx3+WLeUdtx45kBuOGMAy7eUMbeghGeWbOHZpVvpk96eK8b14crsvvTr2sGf4CVmqPASEZGYt3TzPhZv2sdPLxl2zNErM2NUZjqjMtP58UWn8drKHcwtLOGeeeu5+831nD6gC9Nz+nLhyJ50SNKvUGk9/dSIiEjMy8svomNSPFdmZx7/ySHJifFcMro3l4zuzbayAzz54RbmFmzmtrlL+ekzK7hoVC+m5/Qlp3/nmF+TUNqOCi8REYlpOytqeH7ZNr44oS+pySd2wXyvtPb897RT+NrUQRQU72VuwWZeWLaNxwpKGNCtI1dmZ/KFcX3olda+jaOPbs65mC5KnWt9PzgVXiIiEtMe+WATtQ2NXD8566Tfy8wYn9WF8Vld+Oklw3lx+TbmFpbw21fW8PtX13Dm4O5Mz8nks6dlkJwYf/LBR7Hk5GR2795N165dY7L4cs6xe/fuVnezV+ElIiIxq66hkYcWFnPWkO4M6p7Spu/dsV0C03P6Mj2nL8W79/N4YQlPFJbw9YcXk9Y+kcvG9GZ6dl9G9OkUk4XH8WRmZlJSUsLOnTv9DuUw1dXVbbL0DzQVl4e2q2gJFV4iIhKzXlqxndKKGu68or+n++nftSPf/dypfOuzQ8j/eBdzC0qYs2gzsxcUM7RnKldmZ3L52D50TWnnaRyRJDExkQEDBvgdxqfMnz+fsWPH+rZ/FV4iIhKz8vKL6N+1A1OH9AjL/uLjjDMHd+fMwd0pO1DHc0u3MrdgM796YRV3vrSac07rwfTspmWKErRMUSCp8BIRkZi0vKSMwuK9/O/Fx24h4ZW09onMmNifGRP7s3ZHBXMLNvPU4i288pGWKQoyTwsvM0sHHgBGAA74L2AN8CiQBRQBVznn9noZh4iIBM+s/CI6JMUzPad11+B4YUhGKj++aBjfP3+olikKOK/HOf8EvOycGwqMBlYBPwDecM4NBt4I3RcREWkzuypreG7pVq4Yl0mnE2wh4YWDyxTdf30OC390DrdfdBo1dQ3c/vQKJtzxOrc+sph31+2isbH1bQokOng24mVmacBZwEwA51wtUGtmlwFTQ0/LA+YD/+NVHCIiEjxzQi0kcid7e1H9ydAyRcFkJ9L8q0VvbDYGuB9YSdNoVyHwTWCLcy499BwD9h68f8TrbwJuAsjIyMieM2eOJ3EeVFlZSUpK2041jiZBzj/IuUOw81fusZl7faPjtrcO0CfF+N745huaRmr+tQ2OxaUNvLOlno92NeCAUzvHcWZmAuMzEmiXcPLXqkVq7uESjvynTZtW6JzLae4xLwuvHGAhMMU5976Z/QkoB75xaKFlZnudc52P9V45OTmuoKDAkzgPmj9/PlOnTvV0H5EsyPkHOXcIdv7KfarfYXji+WVb+frDi/lHbg7nnJbR7HOiIf9Dlykq2l1Fx6T4NlmmKBpy91I48jezoxZeXl5cXwKUOOfeD91/nKbruXaYWS/n3DYz6wWUehiDiIgEzKz3iujXpQNTTw1PCwmvaJmi2OTZxfXOue3AZjM7NbTpHJpOOz4L5Ia25QLPeBWDiIgEy4otZRQU7+X6Sf2J96GFhBcOLlP0mytH88GPP8tvrxxF99R2/PaVNUy5801y//kBzy/bSk19g9+hSgt43cfrG8C/zSwJ2AB8maZi7zEzuwEoBq7yOAYREQmIWflFtE+MZ3pOX79D8YSWKYp+nhZezrklQHPnOM/xcr8iIhI8uytreHbpVq7KyQxEP6zjLVM0Pacvnx/TO1DLFEUDda4XEZGYMGfRZmrrG8mdlOV3KGF12DJFVXU8u2wrjxds5pfPr+TXL67SMkURRoWXiIhEvfqGRh5aWMwZp3QL9BI8aR0SuW5if647xjJF/Rsb/Q4z0FR4iYhI1Ht15Q62lVXzi8tG+B1KxDjaMkX1jY7Hit/TMkU+UeElIiJRb9Z7RfTt0p7PDI3uFhJeOLhM0bnDMthVWcPvH3+bxfualin65fMrOW94T67K6cvkQV19WUw8aFR4iYhIVPtoaxkfFO3hxxeeFjMtJLzSLaUd52Ul8n9nn6llinyiwktERKJaXqiFxFUx2kLCC2bGqMx0RmWm8+OLTuO1lTuYW1jCPfPWc/eb6zl9QBem5/TlwpE96ZCkUqEt6V9TRESi1p79tTyzZCtXZGeS1kHXKp2I5MR4Lhndm0tG9z5smaLb5i7lp8+s4OJRvZmek0n2SSxTJP+hwktERKLWnEWbqKlvZObkLL9DiQmHLlO0qKhpmaLnlm3l0YLNDOzWkSuyM7liXCY905L9DjVqqfASEZGoVN/QyEMLipk8qCtDAtxCwgtmxoQBXZgwoAs/u3Q4Ly7fxtzCEn77yhp+/+oazhzcnek5mZw7LIN2CfF+hxtVVHiJiEhUem3lDraWVfOzS4f7HUpM0zJFbUuFl4iIRKVZ+UVkdm7POadl+B1KYGiZopOnwktERKLOqm3lvL9xDz+6cKhaSPhAyxSdOBVeIiISdfLyi0hOjFMLiQjQkmWKpmdnBnopp0Op8BIRkaiyd38tTy3ewhfGZZLeIcnvcOQQRy5T9FhomaL7397A6L7pWqYIFV4iIhJlHi3YTE19I7mT+/sdihzFkcsUPb14C3MLSj5Zpuj8ET2Znh3MZYpUeImISNSob2jkwQXFTBrYlaE9O/kdjrRAt5R23HjmQG44Y8BhyxQ9sySYyxSp8BIRkajx+qpStuw7wP9ePMzvUKSVtExRk9jNTEREYs6s/I30SW/PZ0/r4XcochKCvEyRCi8REYkKq7eXs3DDHn5wwVC1KIghQVumSIWXiIhEhbz8ItolxHG1WkjEpKAsU6TCS0REIt6+qqYWEpeP7UPnjmohEeuaW6bo8RhZpkiFl4iIRLxHF22muq6R3MlZfociYXboMkXvrd/F3MLoXqZIhZeIiES0hkbH7AXFnD6gC6f1UguJoIqPM84a0p2zhkT3MkUqvEREJKK9vmoHW/Yd4PaLTvM7FIkQhy5TtGZ7BY8XRs8yRSq8REQkouXlF9E7LZlzh2X4HYpEoFN7Hn2ZojF905me07RMUafkyFimSIWXiIhErDXbK8j/eDffP//UiD59JP472jJFP35qBb947j/LFDU652ucKrxERCRi5S1oaiFxzfh+fociUeRYyxR9eXgSn/ExNhVeIiISkcqq6njqwy1cNqY3XdRCQk5Ac8sU2Y41vsakcVsREYlIjxVs5kBdg1pISJs4uExRSpK/fb9UeImISMRpaHTkLShiQlYXhvdO8zsckTbjaeFlZkVmttzMlphZQWjbGDNbeHCbmU3wMgYREYk+b64upWTvAWZOyfI7FJE2FY5rvKY553Ydcv83wM+dcy+Z2YWh+1PDEIeIiESJWfkb6ZWWzOfUQkJijB+nGh1wsPVwGrDVhxhERCRCrdtRwXvrdzNjYn+1kJCYY87DfhZmthHYS1Ox9Tfn3P1mdhrwCmA0FX6TnXPFzbz2JuAmgIyMjOw5c+Z4FidAZWUlKSkpnu4jkgU5/yDnDsHOX7lHZu55H9XwzpZ6/ji1A6keXQgdyfl7Lci5Q3jynzZtWqFzLqfZB51znn0BfULfewBLgbOAu4ErQtuvAl4/3vtkZ2c7r82bN8/zfUSyIOcf5NydC3b+yj3y7KuqdUNvf8nd9tgST/cTqfmHQ5Bzdy48+QMF7ig1jadjuM65LaHvpcBTwAQgF3gy9JS5oW0iIiLMVQsJiXGeFV5m1tHMUg/eBj4HrKDpmq6zQ0/7DLDOqxhERCR6NDQ6Zi8oZnxWZ0b0UQsJiU1ezmrMAJ4ys4P7edg597KZVQJ/MrMEoJrQdVwiIhJs81aXsmlPFd8//1S/QxHxjGeFl3NuAzC6me3vAtle7VdERKJT3oIienZK5rzhPf0ORcQzmqcrIiK+W19awTvrdjFjYj8S1UJCYph+ukVExHd5+cUkJcTxxQn9/A5FxFMqvERExFfl1XU88WEJl4zqTdeUdn6HI+IpFV4iIuKruQUlVNU2MFMtJCQAVHiJiIhvGhsdsxcUkd2/MyMz1UJCYp8KLxER8c38taUU767SaJcEhgovERHxzb/eKyKjUzvOH6EWEhIMKrxERMQX60srm1pInN5fLSQkMPSTLiIivpi9oIik+Di+eLpaSEhwqPASEZGwK6+u44nCEi4e3YtuaiEhAaLCS0REwu7xghL2q4WEBJAKLxERCauDLSTG9UtnVGa63+GIhJUKLxERCau31u6kaHcVuRrtkgBS4SUiImE1K7+IHqntuGBEL79DEQk7FV4iIhI2H++s5K21O7n29P4kJehXkASPfupFRCRsHlxQTGK88SW1kJCAUuElIiJhUVFdx9yCzVw8qjfdU9VCQoJJhZeIiITFE4VqISGiwktERDzX2OjIW1DMmL7pjO6b7nc4Ir5R4SUiIp57e91ONu7az5enZPkdioivVHiJiIjnZuUX0V0tJERUeImIiLc27trP/DU7ufb0fmohIYGn/wEiIuKpvPwitZAQCVHhJSIinqmsqefxwhIuGtmLHqnJfocj4jsVXiIi4pknPyyhsqZe6zKKhKjwEhERTzQ2OmblFzG6bzpj+3X2OxyRiKDCS0REPPHu+l1s2LmfmZP7+x2KSMRQ4SUiIp6YlV9Et5R2XDhSLSREDlLhJSIiba5o137mrSnlS6f3o11CvN/hiEQMTwsvMysys+VmtsTMCg7Z/g0zW21mH5nZb7yMQUREwm/2gmLizZihFhIih0kIwz6mOed2HbxjZtOAy4DRzrkaM+sRhhhERCRM9tfUM7dgMxeO7EWPTmohIXIoP041fhW40zlXA+CcK/UhBhER8ciTH5ZQUVPPTK3LKPIpXhdeDnjVzArN7KbQtiHAmWb2vpm9ZWbjPY5BRETCxLmmFhKjMtMY2zfd73BEIo4557x7c7M+zrktodOJrwHfAP4CzANuBcYDjwID3RGBhAq1mwAyMjKy58yZ41mcAJWVlaSkpHi6j0gW5PyDnDsEO3/l3va5r9jVwO8KqvnKyCSm9Els8/dvKzr2wcwdwpP/tGnTCp1zOc095uk1Xs65LaHvpWb2FDABKAGeDBVaH5hZI9AN2HnEa+8H7gfIyclxU6dO9TJU5s+fj9f7iGRBzj/IuUOw81fuU9v8fR/KW0S3lEZuu/ozET2bUcd+qt9h+Mbv/D071WhmHc0s9eBt4HPACuBpYFpo+xAgCdh1lLcREZEosWl3FW+sLuVLE9RCQuRovBzxygCeMrOD+3nYOfeymSUB/zSzFUAtkHvkaUYREYk+sxcUEW/GtRPVqV7kaDwrvJxzG4DRzWyvBWZ4tV8REQm//TX1PFqwmQtG9iJDLSREjkqd60VE5KQ9tXgLFdX1WpdR5DhUeImIyElxzpGXX8TIPmmM69fZ73BEIpoKLxEROSn5H+9mXWkluZOzCF3XKyJHocJLREROyr/eK6JrxyQuHtXL71BEIp4KLxEROWGb91TxxuodfHFCP5IT1UJC5HhUeImIyAmbvaCIODOundjP71BEooIKLxEROSFVtfU8umgz54/oSa+09n6HIxIVVHiJiMgJeWrxFsqr65k5OcvvUESihgovERFptYMtJIb37kROf7WQEGkpFV4iItJqCz7ezdodaiEh0loqvEREpNVm5RfRpWMSl47u7XcoIlFFhZeIiLTK5j1VvL5qB9eM76sWEiKtpMJLRERa5aGFxZgZMyZqXUaR1lLhJSIiLXagtoE5izZz3vAMeqerhYRIa6nwEhGRFnt6yRbKDtQxc/IAv0MRiUoqvEREpEWcc8x6r4jTenVifJZaSIicCBVeIiLSIgs37GHNjgq+rBYSIidMhZeIiLTIrPyNdO6QyKVj1EJC5ESp8BIRkeMq2VvFayt3cM2EfmohIXISVHiJiMhxPbiwGEAtJEROkgovERE5pgO1DTy6aDPnDe9JH7WQEDkpKrxEROSYnlmyhX1VdeROzvI7FJGop8JLRESOyjnHrPwihvZM5fQBXfwORyTqqfASEZGjen/jHlZvr2CmWkiItAkVXiIiclR5+UWkd0jksjF9/A5FJCao8BIRkWZt2XeAVz7aztXj+9I+SS0kRNqCCi8REWnWQ6EWEtephYRIm1HhJSIin1Jd18AjH2zi3GEZZHbu4Hc4IjFDhZeIiHzKs0u2sq+qjpmTB/gdikhMUeElIiKHcc7xr/wiTs1IZeJAtZAQaUueFl5mVmRmy81siZkVHPHYd83MmVk3L2MQEZHWWVS0l1Xbypk5RS0kRNpaQhj2Mc05t+vQDWbWF/gcsCkM+xcRkVaYlb+RtPaJfF4tJETanF+nGv8IfB9wPu1fRESasXXfAV75aAfXqIWEiCfMOe9qHzPbCOylqcD6m3PufjO7DPiMc+6bZlYE5Bw5IhZ67U3ATQAZGRnZc+bM8SxOgMrKSlJSUjzdRyQLcv5Bzh2Cnb9y/3Tuj6+t5YUNdfzmrPZ07xC7lwHr2AczdwhP/tOmTSt0zuU095jXpxrPcM5tMbMewGtmthr4EU2nGY/JOXc/cD9ATk6Omzp1qqeBzp8/H6/3EcmCnH+Qc4dg56/cpx62rbqugW+//QbnDstg+oXN/s6IGTr2U/0Owzd+5+/pnzPOuS2h76XAU8DZwABgaWi0KxP40Mx6ehmHiIgc37NLt7K3qo6Zk7P8DkUkZnlWeJlZRzNLPXibplGuRc65Hs65LOdcFlACjHPObfcqDhEROT7nHHn5RQzJSGHSoK5+hyMSs7w81ZgBPBWaipwAPOyce9nD/Z2w+WtK+dvSat4sW0Fa+0TS2ifSKTmRTu0T6dQ+4T/b2ieSkpRAXJymV4tIbCko3stHW8u54/IRaiEh4iHPCi/n3AZg9HGek+XV/lujtKKG9fsaWblkK+XVdRxrvkGcQWrywUIs4bBC7WBx1ql9Ip2SDy/YDj4nKSF2L1YVkeg1K7+ITskJXD5WLSREvBSOPl4R76qcvvSo/JipU6fS2OiorK2n/EAdZaGv8gNN98urD94/5LHqenaUV36yraa+8Zj7ap8Y3/qCLfS9Y1K8/hIVkTa3rewAL6/Yzn9NyaJDkn4tiHhJ/8OOEBdnTacZkxPJ7Nz611fXNVBefbA4O7xgK6s6tHirp+xAHdvLq1mzo4KyA3VUVNcf873j4+yTwqzTsU6JJh850pZAp/aJJMZrtE1EPu3fCzfR6BzXT8ryOxSRmNeiwit0cfwB51yjmQ0BhgIvOefqPI0uCiUnxpOcGE+P1ORWv7ah0VFZXX+UkbXDC7aD97fsO/DJiFxtw7FH2zomxR+1YNu7o5YNCRuPGGn7TzHXPlGjbSKxqLqugYc/2MQ5QzPo26WD3+GIxLyWjni9DZxpZp2BV4FFwNXAtV4FFkTxcUZah0TSOiTSt5Wvdc5RU9/YfMFW1XRK9MjHtuw7wKptTdsqaup5ev3Ko75/Qpy16Bq25q5969Q+kXhNSBCJSM8v28ae/bV8eUqW36GIBEJLCy9zzlWZ2Q3AX5xzvzGzJR7GJa1kZp+MtmV0av1o2xtvziN74pTDrms7fKTt8Ovayg7UsWXvgU+21TceewWElHZNxVjqUQu2hE/uH/lYcmKcRttEPOCcY1b+Rgb3SGGyWkiIhEWLCy8zm0TTCNcNoW1axCuGxMcZ6R2SSO+Q1OrXOuc4UNdweMF2nNOkm/ZUffK8/bUNx3z/pPg4Oh1SmB05snbwfnOjbynJCRptEzmKDzftZcWWcn71ebWQEAmXlhZe3wJ+CDzlnPvIzAYC8zyLSqKKmdEhKYEOSQn0Smv96+saGqlo5lRocwVb+YE69lbVUrx7/yejbw3HGG0z+89o29EKtoR9DUw98fRFota/3isiVS0kRMKqRYWXc+4t4C0AM4sDdjnnbvUyMAmOxPg4unRMokvHExtt21/bcET7j8NPiZYftq2Ojbv2f1LMHahrwIDTRpQy9dQebZ+cSITaW93Iyyu2M3NyFh3baYK7SLi0dFbjw8AtQANNF9Z3MrM/Oed+62VwIsdjZqS0SyClXQK909u3+vXl1XVc9PvX+cbDi3nya5MZnJHqQZQikWfe5noa1EJCJOxa2thpmHOuHPg88BJNC11f51VQIuHSKTmRb41rR7vEeG7IK2DP/lq/QxLxXE19A/M313HO0B7066oWEiLh1NLCK9HMEmkqvJ4N9e869jQ2kSjRtX0c91+fzfbyam55qJDa46w+IBLtXli2jfJayJ2c5XcoIoHT0sLrb0AR0BF428z6A+VeBSUSbuP6dea3V47ig417uP3p5bhjLdgpEsWaWkgU0bujccYp3fwORyRwWlR4Oefuds71cc5d6JoUA9M8jk0krC4b04dvfOYUHiso4R/vbvQ7HBFPLN68j2UlZZzTP1EtJER80KLCy8zSzOwPZlYQ+vo9TaNfIjHl258dwoUje3LHi6t4Y9UOv8MRaXOz3isitV0CU3prJqOIH1p6qvGfQAVwVeirHPiXV0GJ+CUuzvj99DGM6J3GrY8sZs32Cr9DEmkzO8qreXH5Nqbn9CU5QaNdIn5oaeE1yDn3U+fchtDXz4GBXgYm4pf2SfH8/focOrZL4Ia8ReyqrPE7JJE28e/3N4VaSPT3OxSRwGpp4XXAzM44eMfMpgAHvAlJxH8905J5IDeHnRU13PJgITX1x17WSCTS1dQ38PD7m5h2ag+yuulKERG/tLTwugW418yKzKwI+DNws2dRiUSAUZnp/P6q0RQU7+WHT2qmo0S3F5dvY1dlDTPVQkLEVy1dMmgpMNrMOoXul5vZt4BlHsYm4ruLR/Xm49L9/PH1tQzJSOWWswf5HZLICZmVX8zA7h3VQkLEZy0d8QKaCq5QB3uA73gQj0jEufWcU7hkdG/+38urefWj7X6HI9JqizftZenmfcycnEVcnC6qF/FTqwqvI+h/rwSCmfHbK0cxqk8a33p0CSu3qnewRJe8/CJS2iXwhXGZfociEngnU3jpghcJjOTEppmOnZITuTFvEaUV1X6HJNIipRXVvLB8G9NzMklpp95dIn47ZuFlZhVmVt7MVwXQO0wxikSEHp2aZjrurarj5gcLqa7TTEeJfA+/v4m6Bsf1k7L8DkVEOE7h5ZxLdc51auYr1TmnP50kcEb0SeOPV49m8aZ9/M8TyzTTUSJabX0j/35/E9NO7c4AtZAQiQgnc6pRJJDOH9GL7513Ks8s2cq989b7HY7IUb20Yhs7K2rIVQsJkYihUSuRE/C1qYNYt6OC3726lkHdU7hgZC+/QxL5lH+9V8TAbh05a3B3v0MRkRCNeImcADPjzitGMbZfOt9+bAkrtpT5HZLIYZZs3seSzfu4flJ/tZAQiSAqvEROUHJiPPdfl0OXDkncmFfAjnLNdJTIcbCFxBXZaiEhEklUeImchO6p7Xggdzzl1XV8ZXYBB2o101H8V1pRzfPLtnJldiapyYl+hyMih/C08Aqt7bjczJaYWUFo22/NbLWZLTOzp8ws3csYRLw2rHcn/nTNWJZvKeO2x5dqpqP47pH3N4daSPT3OxQROUI4RrymOefGOOdyQvdfA0Y450YBa4EfhiEGEU+dOyyDH5w/lBeWbeNPb6zzOxwJsKYWEsWcPaQ7A7un+B2OiBwh7KcanXOvOufqQ3cXAroAQWLCTWcN5MrsTO56fR3PLd3qdzgSUC+t2EZpRQ0z1UJCJCJ5XXg54FUzKzSzm5p5/L+AlzyOQSQszIw7Lh/B+KzO3DZ3KUs37/M7JAmgvPwisrp24OwhaiEhEonMy+tRzKyPc26LmfWg6RTjN5xzb4ce+zGQA3zBNRNEqFC7CSAjIyN7zpw5nsUJUFlZSUpKcIflg5x/W+deXuv4xYID1DfCTyYl0yU5suew6NjHTu4byxr4+YJqvjQ0ic9lHfui+ljLvbWCnH+Qc4fw5D9t2rTCQy6xOoynhddhOzL7GVDpnPudmc0EbgbOcc5VHe+1OTk5rqCgwNP45s+fz9SpUz3dRyQLcv5e5L5mewVX/DWfrG4deOzmSXRIitxexTr2U/0Oo81857ElvLJiOwt+dA6djjObMdZyb60g5x/k3CE8+ZvZUQsvz/4UN7OOZpZ68DbwOWCFmZ0PfB+4tCVFl0g0OrVnKvd8cSwrt5bz3ceW0tiomY7irV2VNTy/dBtXZGcet+gSEf94eQ4kA3jXzJYCHwAvOOdeBv4MpAKvhdpM3OdhDCK+mTa0Bz+68DReWrGdP7y21u9wJMY98v4mahsauX5Slt+hiMgxeHb+wzm3ARjdzPZTvNqnSKS54YwBrC+t5M/z1nNKjxQ+P7aP3yFJDKpraOSh94s5c3A3TukR3Gt3RKJBZF/1KxLlzIxfXDaC0wd04ftPLKOweK/fIUkMennFdnaU1/DlKVl+hyIix6HCS8RjSQlx3Dcjm15pydz8YAEle3Vpo7StWflF9O/agalDevgdiogchwovkTDo3DGJf+TmUFPXyI15BeyvqT/+i0RaYHlJGYXFe7l+UhZxceZ3OCJyHCq8RMLklB6p/PnacazdUcE35yzRTEdpE7Pyi+iQFM/0HC0CIhINVHiJhNHZQ7rzk4uH8fqqHfzmlTV+hyNRbldlDc8t3coV49RCQiRaRG5XR5EYlTs5i3Wlldz31sec0iOFK7M1UiEnZs4HTS0kcif39zsUEWkhjXiJhJmZ8bNLhzN5UFd++OQyFhXt8TskiUJ1DY08tHBTqIVEqt/hiEgLqfAS8UFifBx/uXYcmZ07cPODhWzeo5mO0jqvfLSd7eXV5KphqkhUUeEl4pP0Dk0zHesbmmY6VlTX+R2SRJG8/CL6denAtKFqISESTVR4ifhoYPcU/jojm/U7K/nmnCU0aKajtMCKLWUsKtrL9ZP6E68WEiJRRYWXiM+mnNKNn186nDdXl3LnS6v8DkeiQF5+Ee0T45me09fvUESklTSrUSQCzJjYn/Wllfz9nY2c0iOFq8f38zskiVC7K2t4ZulWpmdnktZeLSREoo1GvEQixO0XncaZg7tx+9MrWLhht9/hSISas2gztfWNzJyc5XcoInICVHiJRIiE+Dj+/KVx9OvSgVseKqR4936/Q5IIU9/QyEMLi5lySlcGZ6iFhEg0UuElEkHS2ifyj9zxAPzXrEWUa6ajHOLVlTvYVlbNzMkD/A5FRE6QCi+RCJPVrSN/vTab4t1VfP3hxdQ3NPodkkSIWe8Vkdm5PZ9RCwmRqKXCSyQCTRrUlV99fgRvr93Jr17QTEeBj7aW8UHRHnInZamFhEgU06xGkQh1zYR+rCut5B/vNs10nDFR6/EF2cEWElephYRIVNOIl0gE+9GFpzHt1O789NmPyF+/y+9wxCd79tfyzJKtXD6uD2kd1EJCJJqp8BKJYPFxxt1fHMvAbh356r8/ZMPOSr9DEh/MWbSJmvpGrcsoEgNUeIlEuNTkppmO8XHGjXkFlFVppmOQ1Dc08tCCYiYP6sqpPdVCQiTaqfASiQL9unbgvhnZbN5bxdceLqROMx0D47WVO9haVk2uGqaKxAQVXiJRYsKALvzf5SN5b/1ufvHcSr/DkTCZlV9En/T2fPa0DL9DEZE2oMJLJIpMz+nLzWcN5MGFxcxeUOR3OOKxVdvKeX/jHq6f1F8tJERihNpJiESZ758/lI937ufnz60kq2tHzhrS3e+QxCN5+UUkJ8Zx9Xi1kBCJFRrxEoky8XHGXdeMYXCPFP774Q9ZX6qZjrFo7/5anlq8hcvH9iG9Q5Lf4YhIG1HhJRKFUtol8EBuDu0S4rghbxF799f6HZK0sUcLNje1kNBF9SIxRYWXSJTK7NyBv12Xw7Z91Xz134XU1mumY6yob2jkwQXFTBzYhaE9O/kdjoi0IRVeIlEsu39n/t+VI1m4YQ8/fXYFzjm/Q5I28PqqUrbsO8DMyQP8DkVE2pgurheJcpePzWR9aSX3zvuYU3qkcsMZ+mUd7Wblbwy1kOjhdygi0sY8HfEysyIzW25mS8ysILSti5m9ZmbrQt87exmDSBB899xTOW94Bne8sJJ5q0v9DkdOwurt5SzcsIfrJvUnIV4nJURiTTj+V09zzo1xzuWE7v8AeMM5Nxh4I3RfRE5CXJzxx6vHMLRnJ77xyGLW7qjwOyQ5QXn5xbRLiOPqHLWQEIlFfvw5dRmQF7qdB3zehxhEYk6HpKaZju2T4rkhbxG7K2v8DklaaV9VLU8tLuHysX3o3FEtJERikXl5Ma6ZbQT2Ag74m3PufjPb55xLDz1uwN6D94947U3ATQAZGRnZc+bM8SxOgMrKSlJSUjzdRyQLcv6xlvuGfQ38+oNqBqTF8b3xySQep+N5rOXfGpGW+0sb63h0TS2/nNKevqne/l0cabmHW5DzD3LuEJ78p02bVnjImb7DeH1x/RnOuS1m1gN4zcxWH/qgc86ZWbOVn3PufuB+gJycHDd16lRPA50/fz5e7yOSBTn/WMt9KtBtwFZufWQxr+7uwm+uHEXT3zjNi7X8WyOScm9odNz+/jxOH9CF6y6Z5Pn+Iil3PwQ5/yDnDv7n7+mfVM65LaHvpcBTwARgh5n1Agh915XAIm3s0tG9ufWcwcwtLOHv72zwOxxpgTdW7aBk7wFmqmGqSEzzrPAys45mlnrwNvA5YAXwLJAbelou8IxXMYgE2bfOGcxFI3vx65dW8/rKHX6HI8cxK7+I3mnJnDssw+9QRMRDXo54ZQDvmtlS4APgBefcy8CdwLlmtg74bOi+iLSxuDjjd9NHM6J3Gt+cs5hV28r9DkmOYu2OCvI/3s0MtZAQiXme/Q93zm1wzo0OfQ13zt0R2r7bOXeOc26wc+6zzrk9XsUgEnTtk+L5+/U5pCQncGNeATsrNNMxEs3KL6JdQhzXjO/ndygi4jH9aSUS43qmJfPA9ePZvb+GWx4qpLquwe+Q5BBlVXU89eEWLhvTmy5qISES81R4iQTAyMw0/nDVGAqL9/KjJ5drTccI8ljBZg7UNZCri+pFAkGFl0hAXDiyF989dwhPLt7CX9/62O9whKYWErMXFjEhqwvDe6f5HY6IhIEKL5EA+fpnTuHS0b35zctreHnFdr/DCbw3V5eyec8BZk7J8jsUEQkTrxuoikgEMTN+c+UoNu2p4tuPLiGzs/eNOuXo8vKL6JWWzOfUQkIkMDTiJRIwyYnx3H99Np07JPKV2QXsq270O6RAWrejgnfX72LGRLWQEAkS/W8XCaAeqcn8PTeHfVV13L24RjMdfZC3oIikhDi+OEEtJESCRIWXSEAN753GXdeMYUNZI997fJlmOoZR2YE6nijcwmWj1UJCJGhUeIkE2HnDe3LlkESeW7qVe95c73c4gTFXLSREAksX14sE3EUDEmns2IM/vLaWQd1TuGhUL79DimkNjY7ZC4oZn9WZEX3UQkIkaDTiJRJwZsavrxhJdv/OfHfuEpaV7PM7pJg2f00pm/ZUabRLJKBUeIkI7RLi+dt12XTt2I6vzC5ge1m13yHFrFn5RfTslMx5w3v6HYqI+ECFl4gA0C2lHQ/k5lBZXc9XZhdwoFYzHdva+tIK3lm3ixkT+5GoFhIigaT/+SLyidN6deJP14xlxdYyvjt3CY2NmunYlvLyi9VCQiTgVHiJyGE+OyyDH14wlBeXb+euN9b5HU7MKK+u44kPS7hkVG+6prTzOxwR8YlmNYrIp3zlzIGs21HJ3W+sY1D3jlw2po/fIUW9uQUlVNU2MFMX1YsEmka8RORTzIw7Lh/JhAFd+N7jy1i8aa/fIUW1xkbH7AVFZPfvzMhMtZAQCTIVXiLSrKSEOO6bkU1Gp3Z8ZXYhW/cd8DukqDV/bSnFu9VCQkRUeInIMXTpmMQ/c8dTU9fADXkF7K+p9zukqDQrv5iMTu24YIRaSIgEnQovETmmwRmp3P2lsazZXs63H9VMx9b6eGclb6/dybWn91cLCRFR4SUixzft1B7cftEwXl25g9+9usbvcKLK7PwikuLVQkJEmmhWo4i0yJenZLGutJK/zP+YU3qk8IVxmX6HFPEqqut4vLCEi0f1onuqWkiIiEa8RKSFzIxfXDaciQO78IMnllNYvMfvkCLe44Ul7K9t0EX1IvIJFV4i0mKJ8XH89dpseqcnc9PsQkr2VvkdUsRqbHTk5Rcxtl86o/um+x2OiEQIFV4i0iqdOybxQO54ahsauTGvgErNdGzWW+t2UrS7Sg1TReQwKrxEpNVO6ZHCX64dx7rSSr75yGIaNNPxU2a9V0T31HZcMKKX36GISARR4SUiJ+TMwd356SXDeGN1Kb95ebXf4USUDTsreWvtTmac3p+kBH3Mish/aFajiJyw6ydlsW5HJX97ewODeqRwVU5fv0OKCLMXFJMYb3zxdP17iMjh9KeYiJyUn1wyjDNO6caPn1rOBxs10/E/LSR60yM12e9wRCTCqPASkZOSGB/HvV8aR9/OHbj5wQI27Q72TMcnCkuorKlXCwkRaZbnhZeZxZvZYjN7PnT/HDP70MyWmNm7ZnaK1zGIiLfSOiTyj5njaXRwQ94iKqrr/A7JF42NjtkLihnTN50xaiEhIs0Ix4jXN4FVh9z/K3Ctc24M8DBwexhiEBGPDejWkb9eO46Nu/bzjYDOdHx73U427NqvFhIiclSeFl5mlglcBDxwyGYHdArdTgO2ehmDiITP5FO68fPLhjN/zU7ueGHV8V8QY/Lym1pIXDhSLSREpHnmnHd/lZrZ48CvgVTgNufcxWZ2JvA0cAAoByY658qbee1NwE0AGRkZ2XPmzPEsToDKykpSUlI83UckC3L+Qc4dvMn/36tqeK24npnDk5jaN7FN37sttWXu2/c38oN3DnDZoEQuH5zUJu/pJf3cBzf/IOcO4cl/2rRphc65nGYfdM558gVcDPwldHsq8Hzo9pPA6aHb3wMeON57ZWdnO6/NmzfP831EsiDnH+TcnfMm/7r6Bnf9P953g374gntv/c42f/+20pa5/+zZFe6UH73gdpQdaLP39JJ+7uf5HYJvgpy7c+HJHyhwR6lpvDzVOAW41MyKgDnAZ8zsBWC0c+790HMeBSZ7GIOI+CAhPo57vjSWrG4d+epDH7Jx136/Q/JUZU09cwtKuHBkL3p0UgsJETk6zwov59wPnXOZzrks4BrgTeAyIM3MhoSedi6HX3gvIjGiU3Ii/8jNIc6aZjqWHYjdmY5PftjUQkIX1YvI8YS1j5dzrh74CvCEmS0FrqPpdKOIxKD+XTty34xsNu+p4usPf0h9Q6PfIbW5xkbHrPwiRmemMbZfZ7/DEZEIF5bCyzk33zl3cej2U865kc650c65qc65DeGIQUT8cfrArvzq8yN4Z90ufvn8Sr/DaXPvrt/Fhp37mTkly+9QRCQKaK1GEfHc1eP7sb60kr+/s5FTeqRw3aQsv0NqM7Pyi+iWkqQWEiLSIloySETC4gcXnMZnhvbgZ8+t5N11u/wOp00U7drPvDWlfOn0/rRLiPc7HBGJAiq8RCQs4uOMP10zhlO6p/C1fxfy8c5Kv0M6abMXFBNvxrWn9/M7FBGJEiq8RCRsUpMTeSA3h8T4OG7MK2BfVa3fIZ2w/TX1zC3YzIUje5GhFhIi0kIqvEQkrPp26cB912WzZe8BvvbvD6mL0pmOT35YQkVNPblqISEiraDCS0TCbnxWF/7vCyPJ/3g3P332o4OrXUQN55paSIzKTGNcv3S/wxGRKKLCS0R8cWV2JrecPYiH399EXn6R3+G0yrvrd/Hxzv3kTsrCzPwOR0SiiNpJiIhvvn/eqXy8s5JfPL+SrG4dmXpqD79DapG8UAuJi0erhYSItI5GvETEN3Fxxl1Xj+HUnp34xsOLWbejwu+QjmvT7ireWF3KFyf0UwsJEWk1FV4i4quO7RJ4IDeHdonx3JBXwJ79kT3TcfaColALif5+hyIiUUiFl4j4rk96e+6/Ppvt5dXc8lAhtfWROdNxf009jxZs5vwRPemZphYSItJ6KrxEJCKM69eZ3145ig827uH2p5dH5EzHpxZvoaK6ni9rXUYROUG6uF5EIsZlY/qwvrSSe95cz5CMVG48c6DfIX3COUdefhEj+nRiXL/OfocjIlFKI14iElG+/dkhXDCiJ3e8uIo3Vu3wO5xP5H+8m3WllcycPEAtJETkhKnwEpGIEhdn/P6q0Qzv3YlbH1nMmu2RMdNxVn4RXTomcfEotZAQkROnwktEIk6HpAT+fn0OHdslcEPeInZV1vgaz+Y9Vby+agdfmtCP5ES1kBCRE6fCS0QiUq+09vz9+hx2VtRwy4OF1NQ3+BbLgwuLiTPj2on9fItBRGKDCi8RiVij+6bz+6tGU1C8lx8+6c9Mx6raeuZ8sInzR/SkV1r7sO9fRGKLZjWKSES7eFRv1pdWctfr6xiSkcotZw8K6/6fXryV8up6Zk7OCut+RSQ2qfASkYj3zXMGs760kv/38moGduvI54b3DMt+nXPMyt/I8N6dyOmvFhIicvJ0qlFEIp6Z8bvpoxnVJ41vPbqElVvLw7LfBRt2s3ZHJbmTs9RCQkTahAovEYkKyYnx3H99Dp2SE7kxbxGlFdWe73PWe00tJC4d3dvzfYlIMKjwEpGokdEpmQdyc9hTVcvNDxZSXefdTMeDLSSuGd9XLSREpM2o8BKRqDKiTxp/vGoMizft43+eWObZTMeHFhZjZsyY2N+T9xeRYFLhJSJR54KRvbjtc0N4ZslW7p23vs3f/0BtA3MWbea84Rn0TlcLCRFpO5rVKCJR6b+nncL60kp+9+paBnVP4YKRbbeUz9NLtlB2oI6Zkwe02XuKiIBGvEQkSpkZd14xirH90vn2Y0tYsaWsTd7XOUdefhGn9erE+Cy1kBCRtqXCS0SiVnJiPPdfl0OXDkncmFfAjvKTn+m4cMMeVm+v4MtqISEiHlDhJSJRrXtqOx7IHU95dR1fmV3AgdqTm+mYl19E5w6JXDpGLSREpO15XniZWbyZLTaz50P3zczuMLO1ZrbKzG71OgYRiW3DenfiT9eMZfmWMm57fOkJz3Qs2VvFqyu3c82EfmohISKeCMeI1zeBVYfcnwn0BYY6504D5oQhBhGJcecOy+B/zh/KC8u28ac31p3Qezy0cBOAWkiIiGc8LbzMLBO4CHjgkM1fBX7hnGsEcM6VehmDiATHzWcN5Ipxmdz1+jqeW7q1Va+trmtgzqJNnDe8J33UQkJEPOL1iNddwPeBxkO2DQKuNrMCM3vJzAZ7HIOIBISZ8X9fGEFO/87cNncpSzfva/Frn1myhX1VdeROzvIsPhER86rrs5ldDFzonPuamU0FbnPOXWxmlcBPnXO/N7MvAN92zp3ZzOtvAm4CyMjIyJ4zx9szkpWVlaSkpHi6j0gW5PyDnDvEZv7ltY5fLDhAfSP8ZFIyXZKb/xvzYO7OOX6S3zQj8heTkwMxmzEWj3trBDn/IOcO4cl/2rRphc65nGYfdM558gX8GigBioDtQBXwELAaGBB6jgFlx3uv7Oxs57V58+Z5vo9IFuT8g5y7c7Gb/+pt5W7Y/77kLrr7bbe/pq7Z5xzMfeHHu1z//3nePfJ+cRgj9FesHveWCnL+Qc7dufDkDxS4o9Q0np1qdM790DmX6ZzLAq4B3nTOzQCeBqaFnnY2sNarGEQkuE7tmco9XxrLR1vL+e5jS2lsPPro/qz8ItI7JHLZmD5hjFBEgsiPPl53AleY2XKaRsVu9CEGEQmAzwzN4McXnsZLK7bzx9eb/xtvy74DvLpyB1eP70v7JLWQEBFvhWWtRufcfGB+6PY+mmY6ioh47oYzBrBuRyX3vLmeQd1T+PzYw0e1HlpYjHOO69RCQkTCQJ3rRSSmmRm//PwIJgzowvefWEZh8d5PHqttcMz5YBPnDssgs3MHH6MUkaBQ4SUiMS8pIY77ZmTTs1MyNz9YQMneKgAWbqtnb1UdMycP8DlCEQkKFV4iEghdOibxj9wcauoauTGvgP019bxeXM+pGalMHNjF7/BEJCBUeIlIYAzOSOXP145j7Y4Kpt+3gE0VjeROzgpE3y4RiQwqvEQkUM4e0p2fXDyMldvK6ZgInx/b2++QRCRAwjKrUUQkkuROzqKuwbF7ywY6JOljUETCRyNeIhI4ZsZXzhrIxF4qukQkvFR4iYiIiISJCi8RERGRMFHhJSIiIhImKrxEREREwkSFl4iIiEiYqPASERERCRMVXiIiIiJhosJLREREJExUeImIiIiEiQovERERkTBR4SUiIiISJiq8RERERMJEhZeIiIhImJhzzu8YjsvMdgLFHu+mG7DL431EsiDnH+TcIdj5K/fgCnL+Qc4dwpN/f+dc9+YeiIrCKxzMrMA5l+N3HH4Jcv5Bzh2Cnb9yD2buEOz8g5w7+J+/TjWKiIiIhIkKLxEREZEwUeH1H/f7HYDPgpx/kHOHYOev3IMryPkHOXfwOX9d4yUiIiISJhrxEhEREQmTwBVeZna+ma0xs/Vm9oNmHm9nZo+GHn/fzLJ8CNMTLch9ppntNLMloa8b/YjTC2b2TzMrNbMVR3nczOzu0L/NMjMbF+4YvdSC/KeaWdkhx/4n4Y7RK2bW18zmmdlKM/vIzL7ZzHNi8vi3MPdYPvbJZvaBmS0N5f/zZp4Tk5/5Lcw9Zj/zAcws3swWm9nzzTzm33F3zgXmC4gHPgYGAknAUmDYEc/5GnBf6PY1wKN+xx3G3GcCf/Y7Vo/yPwsYB6w4yuMXAi8BBkwE3vc75jDnPxV43u84Pcq9FzAudDsVWNvMz35MHv8W5h7Lx96AlNDtROB9YOIRz4nVz/yW5B6zn/mh/L4DPNzcz7efxz1oI14TgPXOuQ3OuVpgDnDZEc+5DMgL3X4cOMfMLIwxeqUluccs59zbwJ5jPOUyYLZrshBIN7Ne4YnOey3IP2Y557Y55z4M3a4AVgF9jnhaTB7/FuYes0LHszJ0NzH0deSFzTH5md/C3GOWmWUCFwEPHOUpvh33oBVefYDNh9wv4dMfQp88xzlXD5QBXcMSnbdakjvAFaFTLY+bWd/whBYRWvrvE8smhU5LvGRmw/0Oxguh0wljafrr/1Axf/yPkTvE8LEPnW5aApQCrznnjnrsY+wzvyW5Q+x+5t8FfB9oPMrjvh33oBVecmzPAVnOuVHAa/znrwGJfR/StMTFaOAe4Gl/w2l7ZpYCPAF8yzlX7nc84XSc3GP62DvnGpxzY4BMYIKZjfA5pLBpQe4x+ZlvZhcDpc65Qr9jaU7QCq8twKEVfWZoW7PPMbMEIA3YHZbovHXc3J1zu51zNaG7DwDZYYotErTkZyNmOefKD56WcM69CCSaWTefw2ozZpZIU+Hxb+fck808JWaP//Fyj/Vjf5Bzbh8wDzj/iIdi9TP/E0fLPYY/86cAl5pZEU2X1XzGzB464jm+HfegFV6LgMFmNsDMkmi6oO7ZI57zLJAbun0l8KYLXX0X5Y6b+xHXtFxK0/UgQfEscH1odttEoMw5t83voMLFzHoevL7BzCbQ9NkQE798Qnn9A1jlnPvDUZ4Wk8e/JbnH+LHvbmbpodvtgXOB1Uc8LSY/81uSe6x+5jvnfuicy3TOZdH0u+5N59yMI57m23FPCMdOIoVzrt7Mvg68QtMsv3865z4ys18ABc65Z2n6kHrQzNbTdDHyNf5F3HZamPutZnYpUE9T7jN9C7iNmdkjNM3e6mZmJcBPabrYFOfcfcCLNM1sWw9UAV/2J1JvtCD/K4Gvmlk9cAC4JhZ++YRMAa4DloeudwH4EdAPYv74tyT3WD72vYA8M4unqaB8zDn3fBA+82lZ7jH7md+cSDnu6lwvIiIiEiZBO9UoIiIi4hsVXiIiIiJhosJLREREJExUeImIiIiEiQovERERkTBR4SUiUc/MfmxmH4WWPlliZqe34rW3mNn1XsYnInKQ2kmISFQzs0nAH4CpzrmaUNf1JOfc1ha8NiG0TpuISFgEqoGqiMSkXsCug0ufOOd2AZhZNk0FWQqwC5jpnNtmZvOBJcAZwCNmlgpUOud+Z2aDgHuB7jQ1Uv2Kc261mU2nqelsA01d7c8KZ4IiEjt0qlFEot2rQF8zW2tmfzGzs0PrE94DXOmcywb+CdxxyGuSnHM5zrnfH/Fe9wPfCL3mNuAvoe0/Ac4LLSR9qafZiEhM04iXiEQ151xlaHTrTGAa8CjwK2AE8FpoGcJ44NC1Fx898n3MLAWYDMwNvQagXej7e8AsM3sMaG6RbRGRFlHhJSJRzznXAMwH5pvZcuC/gY+cc5OO8pL9zWyLA/Y558Y08/63hC7YvwgoNLNs51xMLCQtIuGlU40iEtXM7FQzG3zIpjHAKqB76MJ7zCzRzIYf632cc+XAxtD1XFiT0aHbg5xz7zvnfgLsBPp6kIqIBIBGvEQk2qUA95hZOlAPrAduoul6rbvNLI2mz7q7gI+O817XAn81s9uBRGAOsBT4bai4M+CN0DYRkVZTOwkRERGRMNGpRhEREZEwUeElIiIiEiYqvERERETCRIWXiIiISJio8BIREREJExVeIiIiImGiwktEREQkTFR4iYiIiITJ/wdIvt0rkCzFLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss, label=\"Loss\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QE_rrOVFWXjm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput=[]\\nground_truth=[]\\npred_series=[]\\ntruth_series=[]\\nloss=[]\\npred_total=[]\\ny_total=[]\\n\\n\\nfor i in range(X_test.size(0)):\\n  curent_X_test=X_test[i,:,:,:]\\n  current_y_test=y_test[i,:,:,:]\\n  pred=model(curent_X_test,current_y_test)\\n  pred=pred[:,-horizon:,:]\\n  pred=pred.reshape(-1,1).detach().numpy()\\n  current_y_test=current_y_test.reshape(-1,1).detach().numpy()\\n\\n  loss.append(loss_fun(torch.tensor(pred),torch.tensor(current_y_test)))\\n  \"\"\\n  plt.figure(figsize=(10, 6))\\n  plt.plot(current_y_test, label=\\'Ground Truth\\')\\n  plt.plot(pred, label=\\'Predicted\\')\\n  plt.title(f\\'Time Series {i+1}: Ground Truth vs Predicted Values\\')\\n  plt.xlabel(\\'Time\\')\\n  plt.ylabel(\\'Value\\')\\n  plt.legend()\\n  plt.grid(True)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "output=[]\n",
    "ground_truth=[]\n",
    "pred_series=[]\n",
    "truth_series=[]\n",
    "loss=[]\n",
    "pred_total=[]\n",
    "y_total=[]\n",
    "\n",
    "\n",
    "for i in range(X_test.size(0)):\n",
    "  curent_X_test=X_test[i,:,:,:]\n",
    "  current_y_test=y_test[i,:,:,:]\n",
    "  pred=model(curent_X_test,current_y_test)\n",
    "  pred=pred[:,-horizon:,:]\n",
    "  pred=pred.reshape(-1,1).detach().numpy()\n",
    "  current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "\n",
    "  loss.append(loss_fun(torch.tensor(pred),torch.tensor(current_y_test)))\n",
    "  \"\"\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.plot(current_y_test, label='Ground Truth')\n",
    "  plt.plot(pred, label='Predicted')\n",
    "  plt.title(f'Time Series {i+1}: Ground Truth vs Predicted Values')\n",
    "  plt.xlabel('Time')\n",
    "  plt.ylabel('Value')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54HD5sDJEb3W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uTFIPGoG0cl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2XE2X1EHo35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C48OZuiIIVzG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GDUWGDSKLji"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wnTTdtOKnMp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "4KSaCeCEoTpw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(53.7491),\n",
       " tensor(53.3235),\n",
       " tensor(45.4637),\n",
       " tensor(60.8301),\n",
       " tensor(58.3371)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1kMfijV0zc2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DbZJI3vY0zrL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput=[]\\nground_truth=[]\\npred_series=[]\\ntruth_series=[]\\nloss=[]\\npred_total=[]\\ny_total=[]\\ntrue_values=[]\\npredicted_values=[]\\n\\nfor i in range(X_test.size(0)):\\n  curent_X_test=X_test[i,:,:,:]\\n  current_y_test=y_test[i,:,:,:]\\n  pred=model(curent_X_test,current_y_test)\\n  pred=pred[:,-horizon:,:]\\n  pred=pred.reshape(-1,1).detach().numpy()\\n  current_y_test=current_y_test.reshape(-1,1).detach().numpy()\\n\\n\\n  loss.append(loss_fun(torch.tensor(pred),torch.tensor(current_y_test)))\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "output=[]\n",
    "ground_truth=[]\n",
    "pred_series=[]\n",
    "truth_series=[]\n",
    "loss=[]\n",
    "pred_total=[]\n",
    "y_total=[]\n",
    "true_values=[]\n",
    "predicted_values=[]\n",
    "\n",
    "for i in range(X_test.size(0)):\n",
    "  curent_X_test=X_test[i,:,:,:]\n",
    "  current_y_test=y_test[i,:,:,:]\n",
    "  pred=model(curent_X_test,current_y_test)\n",
    "  pred=pred[:,-horizon:,:]\n",
    "  pred=pred.reshape(-1,1).detach().numpy()\n",
    "  current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "\n",
    "\n",
    "  loss.append(loss_fun(torch.tensor(pred),torch.tensor(current_y_test)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
