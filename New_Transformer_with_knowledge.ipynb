{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aba1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "import statistics \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6994c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed = 1111\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a77e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"energy\" #traffic,energy\n",
    "with_knowledge=True #True,False\n",
    "positional_embedding=\"absolute\" #absolute,relative\n",
    "attention=\"vanilla\" #vanilla,autoformer,auto_correlation,autoformer_context_window\n",
    "normalization=\"standard_scalar\"\n",
    "test_with_attention=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6aff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=12\n",
    "horizon=6\n",
    "batch_size=32\n",
    "input_size=1\n",
    "hidden_size=64\n",
    "output_size=1\n",
    "ff_hiddensize=64\n",
    "mask_flag=None\n",
    "attn_head=8\n",
    "label_length=4\n",
    "test_size=1440\n",
    "validation_size=1440\n",
    "context_window=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c865f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset==\"traffic\":\n",
    "    sequence_length=12\n",
    "    df=pd.read_csv(\"D:/Transformer_thesis/Dataset/V_228.csv\",header=None)\n",
    "    df_know=pd.read_csv(\"D:/Transformer_thesis/Dataset/final_knowledge/final/traffic/horizon_9/t_preds.csv\", header=None)\n",
    "else:\n",
    "    sequence_length=12\n",
    "    df=pd.read_csv(\"D:\\Transformer_thesis\\Dataset\\energydata_complete.txt\",header=None)\n",
    "    df_know=pd.read_csv(\"D:/Transformer_thesis/Dataset/final_knowledge/final/energy/horizon_6/t_preds.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89cf90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.iloc[:,:5]\n",
    "df_know=df_know.iloc[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283e5a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>46.560000</td>\n",
       "      <td>25.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19731</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>25.754000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.596667</td>\n",
       "      <td>25.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19733</th>\n",
       "      <td>420</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.990000</td>\n",
       "      <td>25.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19734</th>\n",
       "      <td>430</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>25.264286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19735 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1          2          3          4\n",
       "0       60  30  19.890000  47.596667  19.200000\n",
       "1       60  30  19.890000  46.693333  19.200000\n",
       "2       50  30  19.890000  46.300000  19.200000\n",
       "3       50  40  19.890000  46.066667  19.200000\n",
       "4       60  40  19.890000  46.333333  19.200000\n",
       "...    ...  ..        ...        ...        ...\n",
       "19730  100   0  25.566667  46.560000  25.890000\n",
       "19731   90   0  25.500000  46.500000  25.754000\n",
       "19732  270  10  25.500000  46.596667  25.628571\n",
       "19733  420  10  25.500000  46.990000  25.414000\n",
       "19734  430  10  25.500000  46.600000  25.264286\n",
       "\n",
       "[19735 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b886c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "   \n",
    "   test_size=1440\n",
    "   validation_size=1440\n",
    "   train_data=data[:-test_size - validation_size]\n",
    "   \n",
    "   validation_data=data[-test_size - validation_size-12:-test_size]\n",
    "   test_data=data[-test_size-12:]\n",
    "   return train_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5155c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_know(data):\n",
    "   \n",
    "   test_size=1440\n",
    "   validation_size=1440\n",
    "   train_data=data[:-test_size - validation_size]\n",
    "\n",
    "   validation_data=data[-test_size - validation_size:-test_size]\n",
    "   test_data=data[-test_size:]\n",
    "   return train_data,validation_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd02cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_sequences(data,window_size,forecast_horizon):\n",
    "  #X=[]\n",
    "  #y=[]\n",
    "  X_shape=[(len(data)-window_size-forecast_horizon + 1),window_size]\n",
    "\n",
    "  y_shape=[(len(data)-window_size-forecast_horizon + 1),forecast_horizon]\n",
    "  X=np.zeros(X_shape)\n",
    "  y=np.zeros(y_shape)\n",
    "  for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "        _x = data[i:(i+window_size)]\n",
    "        #_y = data[i+window_size]\n",
    "        _y=data[i + window_size:i + window_size + forecast_horizon]\n",
    "        X[i,:]=_x\n",
    "        y[i,:]=_y\n",
    "  \n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d8449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_sequences_seq_normalized(data,window_size,forecast_horizon):\n",
    "    X_shape=[(len(data)-window_size-forecast_horizon + 1),window_size]\n",
    "    y_shape=[(len(data)-window_size-forecast_horizon + 1),forecast_horizon]\n",
    "    X=np.zeros(X_shape)\n",
    "    y=np.zeros(y_shape) \n",
    "    \n",
    "    for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "        _x = data[i:(i+window_size)]\n",
    "        #_y = data[i+window_size]\n",
    "        _y = data[i + window_size:i + window_size + forecast_horizon]\n",
    "        \n",
    "        #print(_x.shape)\n",
    "        min_val_x=_x.min()\n",
    "        max_val_x=_x.max()\n",
    "        denom_x=max_val_x-min_val_x\n",
    "        if(denom_x == 0):\n",
    "            denom_x=max_val_x\n",
    "        \n",
    "        min_val_y=_y.min()\n",
    "        max_val_y=_y.max()\n",
    "        denom_y=max_val_y-min_val_y\n",
    "        if(denom_y==0):\n",
    "            denom_y=max_val_y\n",
    "        \n",
    "        _x_norm = (_x-min_val_x)/denom_x\n",
    "        _y_norm = (_y-min_val_y)/denom_y\n",
    "        \n",
    "        #if(denom_x==0):\n",
    "        X[i,:]=_x_norm\n",
    "        y[i,:]=_y_norm\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e1f07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little bit overlap!!\n",
    "def create_test_seq_new(data, window_size, horizon):\n",
    "    length=data.shape[0]-window_size\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "\n",
    "    data = np.append(data,np.zeros([horizon-extra]))\n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "        \n",
    "    output=np.zeros([i_val,window_size])\n",
    "    y=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[i*horizon:(i*horizon)+window_size]\n",
    "        y[i,:]= data[(i*horizon)+window_size:(i*horizon)+window_size+horizon]\n",
    "        \n",
    "    return output.reshape(output.shape[0],window_size), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e614571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_sequences_seq_normalized(data, window_size,forecast_horizon):\n",
    "    length=data.shape[0]-window_size\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "\n",
    "    data = np.append(data,np.zeros([horizon-extra]))\n",
    "    \n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "        \n",
    "    output=np.zeros([i_val,window_size])\n",
    "    y=np.zeros([i_val,horizon])\n",
    "    \n",
    "    X_scaled_min=np.zeros([i_val,1])\n",
    "    X_scaled_max=np.zeros([i_val,1])\n",
    "    \n",
    "    y_scaled_min=np.zeros([i_val,1])\n",
    "    y_scaled_max=np.zeros([i_val,1])\n",
    "    \n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[i*horizon:(i*horizon)+window_size]\n",
    "        y[i,:]= data[(i*horizon)+window_size:(i*horizon)+window_size+horizon]\n",
    "        \n",
    "        min_val_x=output.min()\n",
    "        max_val_x=output.max()\n",
    "        denom_x=max_val_x-min_val_x\n",
    "        if(denom_x == 0):\n",
    "            denom_x=1\n",
    "           \n",
    "        min_val_y=y.min()\n",
    "        max_val_y=y.max()\n",
    "        denom_y=max_val_y-min_val_y\n",
    "        if(denom_y == 0):\n",
    "            denom_y=1\n",
    "        \n",
    "        _x_norm = (output-min_val_x)/denom_x\n",
    "        _y_norm = (y-min_val_y)/denom_y\n",
    "        \n",
    "        X_scaled_min[i]= min_val_x\n",
    "        X_scaled_max[i]= max_val_x\n",
    "        \n",
    "        y_scaled_min[i]= min_val_y\n",
    "        y_scaled_max[i]= max_val_y\n",
    "        \n",
    "    return _x_norm.reshape(_x_norm.shape[0],window_size), _y_norm, X_scaled_min, X_scaled_max, y_scaled_min, y_scaled_max  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d5ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_knowledge_seq(data,window_size,horizon):\n",
    "    y_shape=[(len(data)-horizon + 1),horizon]\n",
    "    y_know=np.zeros(y_shape)\n",
    "    \n",
    "    for i in range(len(data)-window_size- horizon + 1):\n",
    "        \n",
    "        _y_know=data[i:i+horizon]\n",
    "        y_know[i,:]=_y_know\n",
    "\n",
    "    return y_know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767bcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_knowledge_sequence_normalized(data, window_size,horizon):\n",
    "    y_shape=[(len(data)-horizon + 1),horizon]\n",
    "    y_know=np.zeros(y_shape)\n",
    "      \n",
    "    for i in range(len(data)-window_size- horizon + 1):\n",
    "        \n",
    "        _y_know=data[i:i+horizon]\n",
    "        y_know[i,:]=_y_know\n",
    "        \n",
    "        min_val_x=y_know.min()\n",
    "        max_val_x=y_know.max()\n",
    "        denom_x=max_val_x-min_val_x\n",
    "        if(denom_x == 0):\n",
    "            denom_x=1\n",
    "\n",
    "        y_know_norm = (y_know-min_val_x)/denom_x\n",
    "    return y_know_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb8ef87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also little bit overlap\n",
    "def create_test_k_seq_new(data,horizon):\n",
    "    \n",
    "    length = data.shape[0]\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "    data_app = np.repeat(data[-1],(horizon-extra))\n",
    "    data = np.append(data,data_app)    \n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "    output=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[(i*horizon):(i*horizon)+horizon]\n",
    "        \n",
    "    return output.reshape(output.shape[0],horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0c184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also little bit overlap sequence wise normalized\n",
    "def create_test_k_seq_normalized(data,horizon):\n",
    "    \n",
    "    length = data.shape[0]\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "    data_app = np.repeat(data[-1],(horizon-extra))\n",
    "    data = np.append(data,data_app)    \n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "    output=np.zeros([i_val,horizon])\n",
    "    \n",
    "    y_scaled_know_min=np.zeros([i_val,1])\n",
    "    y_scaled_know_max=np.zeros([i_val,1])\n",
    "    \n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[(i*horizon):(i*horizon)+horizon]\n",
    "        \n",
    "        min_val_y=output.min()\n",
    "        max_val_y=output.max()\n",
    "        denom_y=max_val_y-min_val_y\n",
    "        if(denom_y == 0):\n",
    "            denom_y=1\n",
    "            \n",
    "        _output_norm = (output-min_val_y)/denom_y\n",
    "        \n",
    "        y_scaled_min[i]= min_val_y\n",
    "        y_scaled_max[i]= max_val_y\n",
    "        \n",
    "    return _output_norm.reshape(_output_norm.shape[0],horizon),y_scaled_min,y_scaled_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4acf1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_attention_seq_normalized(data,window_size,forecast_horizon,context_window):\n",
    "  X_attention=[]\n",
    "  end_index=0\n",
    "  \n",
    "  for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "      if end_index < context_window:\n",
    "         _x=data[0:window_size+i]\n",
    "         end_index=window_size+i\n",
    "         zeros_to_add=[0]*(context_window - len(_x))\n",
    "         _x = pd.concat([ pd.Series(zeros_to_add),_x],ignore_index=True)\n",
    "            \n",
    "         min_val_x=_x.min()\n",
    "         max_val_x=_x.max()\n",
    "         denom_x=max_val_x-min_val_x\n",
    "         if(denom_x == 0):\n",
    "            denom_x=1   \n",
    "         \n",
    "         _x_norm = (_x-min_val_x)/denom_x\n",
    "      else:\n",
    "         _x=data[window_size+i-context_window-1:window_size+i-1]\n",
    "            \n",
    "         min_val_x=_x.min()\n",
    "         max_val_x=_x.max()\n",
    "         denom_x=max_val_x-min_val_x\n",
    "         if(denom_x == 0):\n",
    "            denom_x=1\n",
    "            \n",
    "         _x_norm = (_x-min_val_x)/denom_x   \n",
    "         \n",
    "      X_attention.append(_x_norm)\n",
    "  return X_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa1e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_test_sequences_normalized(data, window_size, forecast_horizon,context_window):\n",
    "   \n",
    "    X_attention=np.zeros((len(data),context_window))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if(i<=int(context_window/sequence_length - 2)):       \n",
    "            subset_x=data[0:i+1]\n",
    "            X_attention[i]=np.concatenate ((np.zeros( sequence_length*((int(context_window/sequence_length)) - (i+1)) ), subset_x.reshape(-1)))   \n",
    "            \n",
    "            min_val_x=X_attention[i].min()\n",
    "            max_val_x=X_attention[i].max()\n",
    "            denom_x=max_val_x-min_val_x\n",
    "            if(denom_x == 0):\n",
    "                denom_x=1   \n",
    "         \n",
    "            X_attention_norm = (X_attention[i]-min_val_x)/denom_x\n",
    "        else:\n",
    "            \n",
    "            start_index=int(i-((context_window/sequence_length)-1))\n",
    "            X_attention[i]=data[start_index:i+1].reshape(-1) \n",
    "            \n",
    "            min_val_x=X_attention[i].min()\n",
    "            max_val_x=X_attention[i].max()\n",
    "            denom_x=max_val_x-min_val_x\n",
    "            if(denom_x == 0):\n",
    "                denom_x=1 \n",
    "            X_attention_norm[i] = (X_attention[i]-min_val_x)/denom_x\n",
    "     \n",
    "    return X_attention_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a820634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No overlap at all\n",
    "\n",
    "def create_test_sequences(data, window_size, forecast_horizon):\n",
    "    #print(f\"data shape:{data.shape} type:{type(data)}\")\n",
    "    num_samples = len(data) // (window_size + forecast_horizon)\n",
    "    X_shape = (num_samples, window_size)\n",
    "    y_shape = (num_samples, forecast_horizon)\n",
    "    X = np.zeros(X_shape)\n",
    "    y = np.zeros(y_shape)\n",
    "    #print(f\"num_samples in test sequences:{num_samples},len(data):{len(data)}, window_size + horizon:{(window_size + horizon)}\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        start_index = i * (window_size + forecast_horizon)\n",
    "        end_index_x = start_index + window_size\n",
    "        end_index_y = end_index_x + forecast_horizon\n",
    "\n",
    "        _x = data[start_index:end_index_x]\n",
    "        _y = data[end_index_x:end_index_y]\n",
    "\n",
    "        X[i, :] = _x\n",
    "        y[i, :] = _y\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f688bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no overlap at all\n",
    "def create_test_knowledge_seq(data,window_size,horizon):\n",
    "    \n",
    "    num_samples = len(data) // (window_size + horizon)\n",
    "    y_shape = (num_samples, horizon)\n",
    "    y_know = np.zeros(y_shape)\n",
    "    #print(f\"num_samples in know sequences:{num_samples},len(data):{len(data)}, window_size + horizon:{(window_size + horizon)} \")\n",
    "    for i in range(num_samples):\n",
    "        start_index = i * (horizon)    \n",
    "        end_index_y = start_index + horizon    \n",
    "        _y_know = data[start_index:end_index_y]     \n",
    "        y_know[i, :] = _y_know\n",
    "\n",
    "    return y_know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5475f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_attention_seq(data,window_size,forecast_horizon,context_window):\n",
    "  X_attention=np.zeros([len(data)-window_size- forecast_horizon + 1 , context_window])\n",
    "  #print(X_attention.shape,len(data)-window_size- forecast_horizon + 1)\n",
    "  end_index=0\n",
    "    \n",
    "  for i in range(len(data)-window_size- forecast_horizon + 1):\n",
    "      \n",
    "      if end_index < context_window-1:\n",
    "         _x=data[0:window_size+i]  \n",
    "         end_index=window_size+i\n",
    "         zeros_to_add=[0]*(context_window - len(_x))\n",
    "         _x = pd.concat([ pd.Series(zeros_to_add),pd.Series(_x)],ignore_index=True)\n",
    "         _x=_x.values  \n",
    "      else:     \n",
    "         _x=data[window_size+i-context_window:window_size+i]\n",
    "         \n",
    "      X_attention[i,:]=_x\n",
    "  \n",
    "  return X_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "365d2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_test_sequences(data, window_size, forecast_horizon,context_window):\n",
    "    \n",
    "    X_attention=np.zeros((len(data),context_window))\n",
    "    \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if(i<=int(context_window/sequence_length - 2)): \n",
    "            \n",
    "            subset_x=data[0:i+1]  \n",
    "            #num_zeros=np.zeros(context_window - subset_x.size)\n",
    "            #X_attention[i]=np.concatenate((num_zeros,subset_x.reshape(-1)))\n",
    "            X_attention[i]=np.concatenate ((np.zeros( window_size*((int(context_window/sequence_length)) - (i+1)) ), subset_x.reshape(-1)))             \n",
    "            \n",
    "            #print(f\"X_attention[i]:{X_attention[i]}\")\n",
    "        else:    \n",
    "            \n",
    "            start_index=int(i-((context_window/sequence_length)-1))\n",
    "            \n",
    "            X_attention[i]=data[start_index:i+1].reshape(-1) \n",
    "            \n",
    "            \n",
    "            \n",
    "    return X_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b448598b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_seq_x=np.zeros([df.shape[1], (len(df)-validation_size-test_size-sequence_length-horizon+1) , sequence_length ])\n",
    "train_seq_y=np.zeros([df.shape[1], (len(df)-validation_size-test_size-sequence_length-horizon+1) , horizon])\n",
    "valid_seq_x=np.zeros([df.shape[1], validation_size-horizon+1  , sequence_length ])\n",
    "valid_seq_y=np.zeros([df.shape[1], validation_size-horizon+1 , horizon ])\n",
    "test_seq_x=np.zeros([df.shape[1], test_size // horizon, sequence_length ])\n",
    "test_seq_y=np.zeros([df.shape[1],  test_size //horizon, horizon])\n",
    "\n",
    "\n",
    "train_attention_x=np.zeros([df.shape[1], ((len(df)-validation_size-test_size-sequence_length-horizon+1)), context_window])\n",
    "valid_attention_x=np.zeros([df.shape[1],  validation_size-horizon+1, context_window])\n",
    "test_attention_x=np.zeros([df.shape[1], test_size // horizon  , context_window])\n",
    "\n",
    "\n",
    "\n",
    "train_know_seq_y=np.zeros([df_know.shape[1], (len(df_know)-validation_size-test_size-horizon+1) , horizon])\n",
    "valid_know_seq_y=np.zeros([df_know.shape[1], validation_size-horizon+1 , horizon ])\n",
    "test_know_seq_y=np.zeros([df_know.shape[1],  test_size // horizon, horizon])\n",
    "#print(f\"test_know_seq_y shape:{test_know_seq_y.shape} , test_seq_y:{test_seq_y.shape}, test_seq_x:{test_seq_x.shape}\")\n",
    "\n",
    "for i in range(df.shape[1]):\n",
    "  train_data,validation_data,test_data = train_test_split(df.iloc[:,i])\n",
    "  train_know_data,validation_know_data,test_know_data = train_test_split_know(df_know.iloc[:,i])\n",
    "  #print(train_data.shape)\n",
    "  #break\n",
    "\n",
    "  \n",
    "    \n",
    "  if normalization!=\"sequence_wise\":\n",
    "        scaler.fit(train_data.values.reshape(-1, 1))\n",
    "        train_data_scaled = scaler.transform(train_data.values.reshape(-1, 1))\n",
    "\n",
    "        scaler.fit(validation_data.values.reshape(-1, 1))\n",
    "        validation_data_scaled = scaler.transform(validation_data.values.reshape(-1, 1))\n",
    "\n",
    "        scaler.fit(test_data.values.reshape(-1, 1))\n",
    "        test_data_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "\n",
    "        scaler.fit(train_know_data.values.reshape(-1,1))\n",
    "        train_know_scaled=scaler.transform(train_know_data.values.reshape(-1,1))\n",
    "    \n",
    "        scaler.fit(validation_know_data.values.reshape(-1,1))\n",
    "        validation_know_scaled=scaler.transform(validation_know_data.values.reshape(-1,1))\n",
    "    \n",
    "        scaler.fit(test_know_data.values.reshape(-1,1))\n",
    "        test_know_scaled=scaler.transform(test_know_data.values.reshape(-1,1))\n",
    "    \n",
    "        train_x,train_y=create_train_sequences(train_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "        #train_x,train_y=create_train_sequences(train_data,sequence_length,horizon)\n",
    "        train_seq_x[i,:,:]=train_x\n",
    "        train_seq_y[i,:,:]=train_y\n",
    "        #train_seq_x.append(train_x)\n",
    "        #train_seq_y.append(train_y)\n",
    "\n",
    "        valid_x,valid_y=create_train_sequences(validation_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "  \n",
    "        #valid_x,valid_y=create_train_sequences(validation_data,sequence_length,horizon)\n",
    "        valid_seq_x[i,:,:]=valid_x\n",
    "        valid_seq_y[i,:,:]=valid_y\n",
    "        #valid_seq_x.append(valid_x)\n",
    "        #valid_seq_y.append(valid_y)\n",
    "\n",
    "        test_x,test_y=create_test_seq_new(test_data_scaled.reshape(-1),sequence_length,horizon)\n",
    "    \n",
    "        #test_x,test_y=create_test_sequences(test_data,sequence_length,horizon)\n",
    "        test_seq_x[i,:,:]=test_x\n",
    "        test_seq_y[i,:,:]=test_y\n",
    "        #test_seq_x.append(test_x)\n",
    "        #test_seq_y.append(test_y)\n",
    "  \n",
    "        train_know_seq_y[i,:,:]=create_train_knowledge_seq(train_know_scaled.reshape(-1),sequence_length,horizon) \n",
    "        valid_know_seq_y[i,:,:]=create_train_knowledge_seq(validation_know_scaled.reshape(-1),sequence_length,horizon)\n",
    "        test_know_seq_y[i,:,:]=create_test_k_seq_new(test_know_scaled.reshape(-1),horizon)\n",
    "        \n",
    "    \n",
    "        train_attention_x[i,:,:]=create_attention_seq(train_data_scaled.reshape(-1),sequence_length, horizon,context_window)\n",
    "        valid_attention_x[i,:,:]=create_attention_seq(validation_data_scaled.reshape(-1),sequence_length, horizon,context_window)\n",
    "        test_attention_x[i,:,:]=create_attention_test_sequences(test_x,sequence_length, horizon,context_window)\n",
    "        \n",
    "        \n",
    "  else:\n",
    "        train_x,train_y=create_train_sequences_seq_normalized(train_data.reshape(-1),sequence_length,horizon)\n",
    "        #train_x,train_y=create_train_sequences(train_data,sequence_length,horizon)\n",
    "        train_seq_x[i,:,:]=train_x\n",
    "        train_seq_y[i,:,:]=train_y\n",
    "        #train_seq_x.append(train_x)\n",
    "        #train_seq_y.append(train_y)\n",
    "\n",
    "        valid_x,valid_y=create_train_sequences_seq_normalized(validation_data.reshape(-1),sequence_length,horizon)\n",
    "  \n",
    "        #valid_x,valid_y=create_train_sequences(validation_data,sequence_length,horizon)\n",
    "        valid_seq_x[i,:,:]=valid_x\n",
    "        valid_seq_y[i,:,:]=valid_y\n",
    "        #valid_seq_x.append(valid_x)\n",
    "        #valid_seq_y.append(valid_y)\n",
    "\n",
    "        test_x,test_y,X_scaled_min, X_scaled_max, y_scaled_min, y_scaled_max=create_test_sequences_seq_normalized(test_data.reshape(-1),sequence_length,horizon)\n",
    "    \n",
    "        #test_x,test_y=create_test_sequences(test_data,sequence_length,horizon)\n",
    "        test_seq_x[i,:,:]=test_x\n",
    "        test_seq_y[i,:,:]=test_y\n",
    "        \n",
    "        X_scaled_min[i,:,:]=X_test_min\n",
    "        X_scaled_max[i,:,:]=X_test_max\n",
    "        y_scaled_min[i,:,:]=y_test_min\n",
    "        y_scaled_max[i,:,:]=y_test_max\n",
    "        #test_seq_x.append(test_x)\n",
    "        #test_seq_y.append(test_y)\n",
    "  \n",
    "        train_know_seq_y[i,:,:]=create_train_knowledge_sequence_normalized(train_know_data.reshape(-1),sequence_length,horizon) \n",
    "        valid_know_seq_y[i,:,:]=create_train_knowledge_sequence_normalized(validation_know_data.reshape(-1),sequence_length,horizon)\n",
    "        test_know_seq_y[i,:,:],y_know_scaled_min,y_know_scaled_max=create_test_k_seq_normalized(test_know_data.reshape(-1),horizon)\n",
    "        \n",
    "        train_attention_x[i,:,:]=create_attention_seq_normalized(train_data,sequence_length, horizon,context_window)\n",
    "        valid_attention_x[i,:,:]=create_attention_seq_normalized(validation_data,sequence_length, horizon,context_window)\n",
    "        test_attention_x[i,:,:]=create_attention_test_sequences_normalized(test_x,sequence_length, horizon,context_window)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79f1baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(train_seq_x,dtype=torch.float32)\n",
    "y_train=torch.tensor(train_seq_y,dtype=torch.float32)\n",
    "X_valid=torch.tensor(valid_seq_x,dtype=torch.float32)\n",
    "y_valid=torch.tensor(valid_seq_y,dtype=torch.float32)\n",
    "X_test=torch.tensor(test_seq_x,dtype=torch.float32)\n",
    "y_test=torch.tensor(test_seq_y,dtype=torch.float32)\n",
    "\n",
    "X_train_attention=torch.tensor(train_attention_x,dtype=torch.float32)\n",
    "X_valid_attention=torch.tensor(valid_attention_x,dtype=torch.float32)\n",
    "X_test_attention=torch.tensor(test_attention_x,dtype=torch.float32)\n",
    "\n",
    "y_know_train_seq=torch.tensor(train_know_seq_y,dtype=torch.float32)\n",
    "y_know_valid_seq=torch.tensor(valid_know_seq_y,dtype=torch.float32)\n",
    "y_know_test_seq=torch.tensor(test_know_seq_y,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f70aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.unsqueeze(-1)\n",
    "X_train=X_train.view(-1,X_train.size(2),X_train.size(3))\n",
    "\n",
    "y_train=y_train.unsqueeze(-1)\n",
    "y_train=y_train.view(-1,y_train.size(2),y_train.size(3))\n",
    "\n",
    "X_valid=X_valid.unsqueeze(-1)\n",
    "X_valid=X_valid.view(-1,X_valid.size(2),X_valid.size(3))\n",
    "\n",
    "y_valid=y_valid.unsqueeze(-1)\n",
    "y_valid=y_valid.view(-1,y_valid.size(2),y_valid.size(3))\n",
    "\n",
    "X_test=X_test.unsqueeze(-1)\n",
    "y_test=y_test.unsqueeze(-1)\n",
    "\n",
    "\n",
    "X_train_attention=X_train_attention.unsqueeze(-1)\n",
    "X_train_attention=X_train_attention.view(-1,X_train_attention.size(-2),X_train_attention.size(3))\n",
    "\n",
    "X_valid_attention=X_valid_attention.unsqueeze(-1)\n",
    "X_valid_attention=X_valid_attention.view(-1,X_valid_attention.size(-2),X_valid_attention.size(3))\n",
    "\n",
    "X_test_attention=X_test_attention.unsqueeze(-1)\n",
    "\n",
    "y_know_train_seq=y_know_train_seq.unsqueeze(-1)\n",
    "Y_know_train_seq=y_know_train_seq.view(-1,y_know_train_seq.size(2),y_know_train_seq.size(3))\n",
    "\n",
    "y_know_valid_seq=y_know_valid_seq.unsqueeze(-1)\n",
    "Y_know_valid_seq=y_know_valid_seq.view(-1,y_know_train_seq.size(2),y_know_train_seq.size(3))\n",
    "\n",
    "Y_know_test_seq=y_know_test_seq.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afdc8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):\n",
    "  def __init__(self,X,y):\n",
    "    self.X=X\n",
    "    self.y=y\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64050e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDataset(Dataset):\n",
    "  def __init__(self,X):\n",
    "    self.X=X\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa1b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDataset(Dataset):\n",
    "  def __init__(self,X):\n",
    "    self.X=X\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "780e1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=TimeseriesDataset(X_train,y_train)\n",
    "valid_dataset=TimeseriesDataset(X_valid,y_valid)\n",
    "test_dataset=TimeseriesDataset(X_test,y_test)\n",
    "\n",
    "train_attention_dataset=AttentionDataset(X_train_attention)\n",
    "valid_attention_dataset=AttentionDataset(X_valid_attention)\n",
    "test_attention_dataset=AttentionDataset(X_test_attention)\n",
    "\n",
    "train_know_dataset=KnowledgeDataset(Y_know_train_seq)\n",
    "valid_know_dataset=KnowledgeDataset(Y_know_valid_seq)\n",
    "test_know_dataset=KnowledgeDataset(Y_know_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6320136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size,drop_last=True)\n",
    "valid_loader=DataLoader(valid_dataset,batch_size,drop_last=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size,drop_last=True)\n",
    "\n",
    "train_attention_loader=DataLoader(train_attention_dataset,batch_size,drop_last=True)\n",
    "valid_attention_loader=DataLoader(valid_attention_dataset,batch_size,drop_last=True)\n",
    "test_attention_loader=DataLoader(test_attention_dataset,batch_size,drop_last=True)\n",
    "\n",
    "train_knowledge_loader=DataLoader(train_know_dataset,batch_size,drop_last=True)\n",
    "valid_knowledge_loader=DataLoader(valid_know_dataset,batch_size,drop_last=True)\n",
    "test_knowledge_loader=DataLoader(test_know_dataset,batch_size,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b8a8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size):\n",
    "      super().__init__()\n",
    "      self.input_size=input_size\n",
    "      self.hidden_size=hidden_size\n",
    "      self.conv1d=nn.Conv1d(in_channels=self.input_size,out_channels=self.hidden_size,padding=1,kernel_size=3,bias=False)\n",
    "  def forward(self,x):\n",
    "      embedded_inp=self.conv1d(x.permute(0,2,1))\n",
    "      return embedded_inp.transpose(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec54290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativePositionalEmbedding(nn.Module):\n",
    "    def __init__(self,head_dim,max_position=512):\n",
    "        super(RelativePositionalEmbedding,self).__init__()\n",
    "        self.pos_embed=nn.Parameter(torch.Tensor(max_position * 2 + 1, head_dim))\n",
    "        nn.init.xavier_uniform_(self.pos_embed)\n",
    "        self.max_position=max_position\n",
    "    def forward(self,query_len,key_len):\n",
    "        query_range=torch.arange(query_len)\n",
    "        key_range=torch.arange(key_len)\n",
    "        relative_matrix=key_range[None,:]-query_range[:,None]\n",
    "        clipped_relative_matrix = torch.clamp(relative_matrix, -self.max_position, self.max_position)\n",
    "        relative_matrix=clipped_relative_matrix+self.max_position \n",
    "        return self.pos_embed[relative_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7b73b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()* -(math.log(10000.0) / d_model)).exp()\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self,x):\n",
    "        return self.pe[:,:x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802a0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationAttentionLayer(nn.Module):\n",
    "  def __init__(self,attn_head,hidden_size):\n",
    "    \n",
    "    \n",
    "    \n",
    "    super(CorrelationAttentionLayer,self).__init__()\n",
    "    self.attn_head=attn_head\n",
    "    self.hidden_size=hidden_size\n",
    "    self.dropout=nn.Dropout(0.1)\n",
    "\n",
    "    self.queries_emb=nn.Linear(hidden_size,hidden_size)\n",
    "    self.keys_emb=nn.Linear(hidden_size,hidden_size)\n",
    "    self.values_emb=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "  def forward(self,q,k,v,attention_mask):\n",
    "    b,l,d=q.shape\n",
    "    b,s,d=k.shape\n",
    "\n",
    "    #Linear projection and creation of multiple heads\n",
    "    queries=self.queries_emb(q).view(b,l,self.attn_head,-1)\n",
    "    keys=self.keys_emb(k).view(b,s,self.attn_head,-1)\n",
    "    values=self.values_emb(v).view(b,s,self.attn_head,-1)\n",
    "\n",
    "    b,l,h,d=queries.shape\n",
    "    b,s,h,d=values.shape\n",
    "\n",
    "    if l > s:\n",
    "            zeros = torch.zeros_like(queries[:, :(l - s), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "    else:\n",
    "            values = values[:, :l, :, :]\n",
    "            keys = keys[:, :l, :, :]\n",
    "\n",
    "    top_k=8\n",
    "\n",
    "    q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "    k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "    \n",
    "    res = q_fft * torch.conj(k_fft)\n",
    "    \n",
    "    corr = torch.fft.irfft(res, n=l, dim=-1)\n",
    "    \n",
    "    mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "    top2_values, top2_indices = torch.topk(mean_value, 2, dim=1)\n",
    "    #print(f\"top2_indices:{top2_indices}\")\n",
    "    #max_value, max_index = torch.max(mean_value, dim=1)\n",
    "    #print(f\"max_index: {max_index}\")\n",
    "    \n",
    "    index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "    weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "\n",
    "    tmp_corr = torch.softmax(weights, dim=-1)\n",
    "\n",
    "    values=values.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    tmp_values = values\n",
    "    delays_agg = torch.zeros_like(values).float()\n",
    "\n",
    "    for i in range(top_k):\n",
    "        pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "        delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, h, d, l))\n",
    "    agg_seq=delays_agg.permute(0, 3, 1, 2).view(b,l,-1)\n",
    "    if attention==\"autoformer_context_window\" and with_knowledge==True:\n",
    "        \n",
    "        return agg_seq[:,:sequence_length+horizon+label_length+horizon,:]\n",
    "    elif attention==\"autoformer_context_window\" and with_knowledge==False:\n",
    "        return agg_seq[:,:label_length+horizon,:]\n",
    "    else:\n",
    "        return agg_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24df2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(seq_win,con_win):\n",
    "    #seq_win_norm=normalize(seq_win)\n",
    "    #con_win_norm=normalize(con_win)\n",
    "    corr=np.correlate(con_win[i].reshape(-1),seq_win[i].reshape(-1),mode=\"valid\")\n",
    "    return corr\n",
    "def get_correlation_seq(seq_win,con_win):\n",
    "    \n",
    "    batch_size=seq_win.shape[0]\n",
    "    correlation_batch_index=np.zeros(batch_size)\n",
    "    correlation_batch_val=np.zeros(batch_size)\n",
    "    correlation_seq=torch.zeros((batch_size,sequence_length,1))\n",
    "    for i in range(batch_size):\n",
    "        seq_win_batch=seq_win[i]\n",
    "        context_win_batch=con_win[i]   \n",
    "        correlation=[]\n",
    "        for j in range(context_window-sequence_length):\n",
    "            sequence_window=seq_win_batch \n",
    "            context_window_data=context_win_batch[j:j+12,:]         \n",
    "            corr=autocorrelation(sequence_window,context_window_data) \n",
    "            correlation.append(corr)\n",
    "        max_correlation=max(correlation)\n",
    "        max_correlation_index=np.argmax(correlation)\n",
    "        \n",
    "        l_a,_=con_win[i,max_correlation_index:max_correlation_index+12,:].shape\n",
    "        if l_a < sequence_length:  \n",
    "            prev_index=sequence_length-l_a  \n",
    "            correlation_seq[i]=con_win[i,max_correlation_index-prev_index:,:]\n",
    "        else:\n",
    "            correlation_seq[i]=con_win[i,max_correlation_index:max_correlation_index+12,:] \n",
    "    return correlation_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d47dcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "  def __init__(self,attn_head,hidden_size):\n",
    "    super().__init__()\n",
    "\n",
    "    self.attn_head=attn_head\n",
    "    self.hidden_size=hidden_size\n",
    "    self.dropout = nn.Dropout(0.01)\n",
    "    self.linear=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "    self.queries=nn.Linear(hidden_size,hidden_size)\n",
    "    self.keys=nn.Linear(hidden_size,hidden_size)\n",
    "    self.values=nn.Linear(hidden_size,hidden_size)\n",
    "\n",
    "  def forward(self, queries,keys,values,attention_mask,return_attention=False):\n",
    "    b,l,d=queries.shape\n",
    "    b,s,d=keys.shape\n",
    "    \n",
    "    #Linear projection and creation of multiple heads\n",
    "    queries=self.queries(queries).view(b,l,self.attn_head,-1)\n",
    "    keys=self.keys(keys).view(b,s,self.attn_head,-1)\n",
    "    values=self.values(values).view(b,s,self.attn_head,-1)\n",
    "\n",
    "    b,l,h,d=queries.shape\n",
    "    b,s,h,d=values.shape\n",
    "\n",
    "    #Calculate attention score\n",
    "    attention_score=torch.einsum(\"blhd,bshd->bhls\",queries,keys)\n",
    "    \n",
    "    if attention_mask == True:\n",
    "       mask_shape = [b,1,l,l]\n",
    "       mask=torch.triu(torch.ones(mask_shape,dtype=torch.bool),diagonal=1)\n",
    "       attention_score.masked_fill_(mask,-np.inf)\n",
    "    attention_score_softmax=self.dropout(torch.softmax(attention_score/sqrt(d),dim=-1))    \n",
    "    final_value=torch.einsum(\"bhls,bshd->blhd\",attention_score_softmax,values)\n",
    "    weighted_attn_val=self.linear(final_value.contiguous().view(b,l,-1))\n",
    "        \n",
    "    if return_attention==True:\n",
    "        return weighted_attn_val,attention_score_softmax\n",
    "    else:\n",
    "        #return weighted_attn_val\n",
    "        #If using context_window for attention \n",
    "        #print(f\"weighted_attn_val:{weighted_attn_val[:,-15:,:].shape}\")\n",
    "        #print(f\"weighted_attn_val shape:{weighted_attn_val.shape}\")\n",
    "        return weighted_attn_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a4162a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeAttention(nn.Module):\n",
    "    def __init__(self, attn_head,hidden_size):\n",
    "        super(RelativeAttention, self).__init__()\n",
    "        self.attn_head=attn_head\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.01)\n",
    "        self.queries=nn.Linear(hidden_size,hidden_size)\n",
    "        self.keys=nn.Linear(hidden_size,hidden_size)\n",
    "        self.values=nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        self.relative_positional_emd=RelativePositionalEmbedding(int(hidden_size/self.attn_head))\n",
    "        self.linear=nn.Linear(hidden_size,hidden_size)\n",
    "    def forward(self, query, key, value,attention_mask,return_attention=False):\n",
    "        b,l,d=query.shape\n",
    "        b,s,d=key.shape\n",
    "        queries=self.queries(query).view(b,l,self.attn_head,-1)\n",
    "        keys=self.keys(key).view(b,s,self.attn_head,-1)\n",
    "        values=self.values(value).view(b,s,self.attn_head,-1)\n",
    "        \n",
    "        b,l,h,d=queries.shape\n",
    "        b,s,h,d=values.shape\n",
    "        \n",
    "        a_key=self.relative_positional_emd(l,s)\n",
    "        a_val=self.relative_positional_emd(l,s)\n",
    "        \n",
    "        qk_attention=torch.einsum(\"blhd,bshd->bhls\",queries,keys)\n",
    "        qk_relative_attention=torch.einsum(f\"blhd,lsd->bhls\",queries,a_key)\n",
    "        \n",
    "        attention_score=qk_attention+qk_relative_attention\n",
    "        \n",
    "        if attention_mask == True:\n",
    "            #print(f\"attn_score:{attn_score.shape}\")\n",
    "            mask_shape = [b,1,l,l]\n",
    "            mask=torch.triu(torch.ones(mask_shape,dtype=torch.bool),diagonal=1)\n",
    "            attention_score.masked_fill_(mask,-np.inf)\n",
    "        attention_score_softmax=self.dropout(torch.softmax(attention_score/sqrt(d),dim=-1))\n",
    "        \n",
    "        weighted_attention=torch.einsum(\"bhls,bshd->blhd\",attention_score_softmax,values)\n",
    "        weighted_attention_rel=torch.einsum(\"bhls,lsd->blhd\",attention_score_softmax,a_val)\n",
    "        \n",
    "        weighted_attention_final=weighted_attention+weighted_attention_rel\n",
    "        weighted_attn_val=self.linear(weighted_attention_final.contiguous().view(b,l,-1))\n",
    "        \n",
    "        if return_attention==True:\n",
    "            return weighted_attn_val,attention_score_softmax\n",
    "        else:\n",
    "            return weighted_attn_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3734f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,attention,hidden_size,output_size):\n",
    "    super(Encoder,self).__init__()\n",
    "    self.attention=attention  \n",
    "    self.conv1=nn.Conv1d(in_channels=hidden_size,out_channels=hidden_size,kernel_size=1)\n",
    "    self.conv2=nn.Conv1d(in_channels=hidden_size,out_channels=hidden_size,kernel_size=1)\n",
    "    self.linear=nn.Linear(hidden_size,hidden_size)\n",
    "    #self.norm1=nn.LayerNorm(normalized_shape=(sequence_length,hidden_size))\n",
    "    self.norm1=nn.LayerNorm(hidden_size)\n",
    "    self.activation=F.gelu\n",
    "    self.dropout=nn.Dropout(0.01)\n",
    "    \n",
    "    self.queries=nn.Linear(hidden_size,hidden_size)\n",
    "    self.keys=nn.Linear(hidden_size,hidden_size)\n",
    "    self.values=nn.Linear(hidden_size,hidden_size)\n",
    "    \n",
    "  def forward(self,x,x_attn=None):\n",
    "        \n",
    "    if test_with_attention==False:\n",
    "        #Skipping attention and passed through FFN only\n",
    "        out=self.conv1(x.permute(0,2,1))\n",
    "        out=self.activation(out)\n",
    "        out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "        norm_out=self.norm1(out)\n",
    "        return norm_out\n",
    "    else:\n",
    "        if attention==\"auto_correlation\":\n",
    "            \n",
    "            attention_x=self.attention(x,x_attn,x_attn,attention_mask=False)\n",
    "        else:\n",
    "            if attention==\"autoformer_context_window\":\n",
    "               attention_x=self.attention(x_attn,x_attn,x_attn,attention_mask=False)\n",
    "               if  with_knowledge==True: \n",
    "                     \n",
    "                     new_x = x + attention_x[:,:sequence_length+horizon,:]\n",
    "               elif with_knowledge==False:\n",
    "                     new_x = x + attention_x[:,:sequence_length,:]\n",
    "            #if attention is vanilla or autoformer attention using sequence_window as Q,K,V instead of context_window\n",
    "            else:\n",
    "               attention_x=self.attention(x,x,x,attention_mask=False) \n",
    "               new_x = x + attention_x\n",
    "        res_x=x=self.norm1(new_x)\n",
    "        ##Feed forward NN:\n",
    "        out=self.conv1(res_x.permute(0,2,1))\n",
    "        out=self.dropout(self.activation(out)) \n",
    "        out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "        ##Add and normalize:\n",
    "        new_out=out+res_x\n",
    "        norm_out=self.norm1(new_out)\n",
    "        \n",
    "        return norm_out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62e3d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,attention,hidden_size,output_size):\n",
    "    super(Decoder,self).__init__()\n",
    "    self.attention=attention\n",
    "    self.conv1=nn.Conv1d(in_channels=hidden_size,out_channels=hidden_size,kernel_size=1)\n",
    "    self.conv2=nn.Conv1d(in_channels=hidden_size,out_channels=hidden_size,kernel_size=1)\n",
    "    self.linear1=nn.Linear(hidden_size,hidden_size)\n",
    "    self.linear2=nn.Linear(hidden_size,hidden_size)\n",
    "    self.linear3=nn.Linear(hidden_size,output_size)\n",
    "    self.dropout=nn.Dropout(0.01)\n",
    "    self.norm1=nn.LayerNorm(hidden_size)\n",
    "    self.norm2=nn.LayerNorm(hidden_size)\n",
    "    self.norm3=nn.LayerNorm(hidden_size)\n",
    "    self.activation=F.relu\n",
    "    \n",
    "  def forward(self,dec_inp,enc_out):\n",
    "    \n",
    "    if test_with_attention==False:\n",
    "        \n",
    "        #FFN\n",
    "        out=self.conv1(enc_out.permute(0,2,1))\n",
    "        out=self.activation(out)\n",
    "        out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "        out=self.norm3(out)\n",
    "        \n",
    "        #Linear projection\n",
    "        pred=self.linear3(out)\n",
    "        return pred\n",
    "    \n",
    "    else:  \n",
    "        \n",
    "        self_attn=self.attention(dec_inp,dec_inp,dec_inp,attention_mask=True)\n",
    "        #add residual connection and normalize\n",
    "        if attention==\"autoformer_context_window\":\n",
    "            if  with_knowledge==True: \n",
    "                residual_add=dec_inp + self_attn[:,:label_length+horizon+horizon,:]\n",
    "            else:\n",
    "                residual_add=dec_inp + self_attn[:,:label_length+horizon,:]\n",
    "        else:\n",
    "            residual_add=dec_inp + self_attn\n",
    "        new_dec_x=self.norm1(residual_add)\n",
    "    \n",
    "        # encoder-decoder attention. Pass encoder output as key and value and queries as output of self-attention of decoder\n",
    "        enc_dec_atten=self.attention(new_dec_x,enc_out,enc_out,attention_mask=False)\n",
    "        \n",
    "        ## add and normalize\n",
    "        new_x=enc_dec_atten+self_attn\n",
    "        norm_x=self.norm2(new_x)\n",
    "    \n",
    "        #FFN\n",
    "        out=self.conv1(norm_x.permute(0,2,1))\n",
    "        out=self.dropout(self.activation(out))\n",
    "        out=self.dropout(self.conv2(out).transpose(-1, 1))\n",
    "\n",
    "        #add and normalize\n",
    "        new_x=out+norm_x\n",
    "        out=self.norm3(new_x)\n",
    "\n",
    "        #Linear projection\n",
    "        pred=self.linear3(out)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a656ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,output_size,attn_head):\n",
    "      super(TransformerModel,self).__init__()\n",
    "      \n",
    "      self.enc_embedding=InputEmbedding(input_size,hidden_size)\n",
    "      self.dec_embedding=InputEmbedding(input_size,hidden_size)\n",
    "        \n",
    "      if positional_embedding==\"absolute\":  \n",
    "            self.enc_positional_embedding=PositionalEmbedding(hidden_size)\n",
    "            self.dec_positional_embedding=PositionalEmbedding(hidden_size)\n",
    "            if attention==\"vanilla\":\n",
    "                    self.encoder=Encoder( AttentionLayer(attn_head,hidden_size),hidden_size,output_size)\n",
    "                    self.decoder=Decoder( AttentionLayer(attn_head,hidden_size),hidden_size,output_size)\n",
    "            elif attention==\"autoformer\" or attention==\"autoformer_context_window\":\n",
    "                    self.encoder=Encoder( CorrelationAttentionLayer(attn_head,hidden_size),hidden_size,output_size)  \n",
    "                    self.decoder=Decoder( CorrelationAttentionLayer(attn_head,hidden_size),hidden_size,output_size)\n",
    "            else:\n",
    "                    #Auto_correlation attention Still uses vanilla self attention mechanism but the parameters passed are different\n",
    "                    self.encoder=Encoder( AttentionLayer(attn_head,hidden_size),hidden_size,output_size)\n",
    "                    self.decoder=Decoder( AttentionLayer(attn_head,hidden_size),hidden_size,output_size)\n",
    "      else:    \n",
    "            #Uses Relative positional embedding\n",
    "            self.encoder=Encoder( RelativeAttention(attn_head,hidden_size),hidden_size,output_size)\n",
    "            self.decoder=Decoder( RelativeAttention(attn_head,hidden_size),hidden_size,output_size)\n",
    "            \n",
    "            \n",
    "            #self.encoders = nn.ModuleList([Encoder(AttentionLayer(self.attn_head, hidden_size), hidden_size, output_size, ff_hiddensize, sequence_length)\n",
    "                                        #for _ in range(2)])\n",
    "            #self.decoders = nn.ModuleList([Decoder( AttentionLayer(self.attn_head,hidden_size),self.hidden_size,self.output_size,self.ff_hidden_size,sequence_length )\n",
    "                                        #for _ in range(2)])\n",
    "                \n",
    "      self.linear=nn.Linear(hidden_size,output_size)\n",
    "      self.dropout=nn.Dropout(0.01) \n",
    "  \n",
    "  def forward(self,x,y,know_pred=None,x_attn=None):\n",
    "        if know_pred is not None:  \n",
    "            #1.For encoder, Integrate knowledge predictions to the sequence_window(x) to get the context vector at the encoder that has- \n",
    "            #-informataion of future using the knowledge predictions\n",
    "            #2.For decoder, when knowledge pred were not used, just the previous four data points from the forecast horizon x[:,-4:,:]\n",
    "            #was included. Now, knowledge predictions are also integrated here.\n",
    "            \n",
    "            encoder_input=torch.cat((x,know_pred),dim=1)\n",
    "            decoder_input=torch.cat((x[:,-4:,:],know_pred,torch.zeros_like(y[:,-horizon:,:])),dim=1)\n",
    "        else:\n",
    "            encoder_input=x\n",
    "            decoder_input=torch.cat((x[:,-4:,:],torch.zeros_like(y[:,-horizon:,:])),dim=1)\n",
    "      \n",
    "        #ENCODER\n",
    "        \n",
    "        #decide here which positional embedding\n",
    "        if positional_embedding==\"absolute\":\n",
    "            inp_embed=self.enc_embedding(encoder_input)\n",
    "            pos_embed=self.enc_positional_embedding(encoder_input)\n",
    "            enc_out=inp_embed + pos_embed\n",
    "            \n",
    "            inp_embed=self.dec_embedding(decoder_input)\n",
    "            pos_embed=self.dec_positional_embedding(decoder_input)\n",
    "            dec_out= inp_embed + pos_embed\n",
    "            if attention==\"autoformer_context_window\":\n",
    "                inp_embed=self.enc_embedding(x_attn)\n",
    "                pos_embed=self.enc_positional_embedding(x_attn)\n",
    "                enc_out_attn_context=inp_embed + pos_embed\n",
    "            \n",
    "        else:  \n",
    "            # In relative positional embedding, the embedding are learnt on the fly by the model during attention. Used Shaw et al., method,\n",
    "            # hence, there is only input embedding,positional embedding part in attention.\n",
    "            enc_out=self.enc_embedding(encoder_input)\n",
    "            dec_out=self.dec_embedding(decoder_input)\n",
    "        \n",
    "        # After input embedding check which attention must be used.\n",
    "        if attention==\"auto_correlation\":\n",
    "            #get the most correlated sequence of \"X\" in \"X_attn(Context_window)\"\n",
    "            corr_seq=get_correlation_seq(x,x_attn) \n",
    "            \n",
    "            attn_inp_embed=self.enc_embedding(corr_seq)\n",
    "            attn_pos_embed=self.enc_positional_embedding(corr_seq)\n",
    "            \n",
    "            attn_enc_out=attn_inp_embed+attn_pos_embed  \n",
    "            enc_out=self.encoder(enc_out,attn_enc_out)\n",
    "        elif attention==\"autoformer_context_window\":\n",
    "            #Since autoformer is designed for longer sequences and we are using short sequence_window=12, we will be\n",
    "            #using a long window by including certain range of data points that occurs before the sequence_window(x_attn).\n",
    "            enc_out=self.encoder(enc_out,enc_out_attn_context)\n",
    "            \n",
    "        else:\n",
    "          # if attention is vanilla attention/autoformer attention:\n",
    "            enc_out=self.encoder(enc_out)\n",
    "            \n",
    "        #decoder      \n",
    "        out=self.decoder(dec_out,enc_out) \n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TransformerModel(input_size,hidden_size,output_size,attn_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db6c3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aca01517",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                   | 1/2 [02:34<02:34, 154.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train_loss:0.8631235018235833 valid_loss:0.9228720510383417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [04:49<00:00, 144.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.7269739701092666 valid_loss:0.74874026145231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "        train_loss=[]\n",
    "        valid_total_loss=[]\n",
    "        model.train()\n",
    "        \n",
    "        if with_knowledge==True and (attention==\"auto_correlation\" or attention == \"autoformer_context_window\"):\n",
    "              for (batch_idx, (X,y)),(batch_idx_2,(know_pred)),(batch_idx_3,(x_attention)) in zip(enumerate(train_loader), enumerate(train_knowledge_loader), enumerate(train_attention_loader)):\n",
    "                    \n",
    "                    #1.Pass the window,forecast horizon,knowledge prediction and a context window of say 120 time points-\n",
    "                    #-that are present upto the end of current window.\n",
    "                    #2.Get the most correlated sequence index and the data points of window_size after the correlated index (np.correlate (context_window,sequence_window)) \n",
    "                    #3.Pass this correlated sequence as keys and values to the attention and sequence_window as query in attention mechanism\n",
    "                    \n",
    "                    pred=model(X,y,know_pred,x_attention)\n",
    "                    pred=pred[:,-horizon:,:]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss=loss_fun(pred,y)\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                    batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "                    \n",
    "                    outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                    batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "                    \n",
    "                    tloss=loss_fun(outputs,batch_y)\n",
    "                    train_loss.append(tloss.item())\n",
    "              train_loss = np.average(train_loss)      \n",
    "        \n",
    "              model.eval()\n",
    "              with torch.no_grad():\n",
    "               for (batch_idx, (X,y)),(batch_idx_2,(know_pred)),(batch_idx_3,(x_attention)) in zip(enumerate(valid_loader), enumerate(valid_knowledge_loader), enumerate(valid_attention_loader)):\n",
    "                    pred=model(X,y,know_pred,x_attention)\n",
    "                    pred=pred[:,-horizon:,:]\n",
    "            \n",
    "                    outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                    batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                    outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                    batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "                \n",
    "                    valid_loss=loss_fun(outputs,batch_y) \n",
    "                    valid_total_loss.append(valid_loss.item())\n",
    "               valid_total_loss=np.average(valid_total_loss)\n",
    "              print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\")      \n",
    "         \n",
    "        elif with_knowledge == True and attention != \"auto_correlation\":  \n",
    "            \n",
    "              # Simple vanilla transformer with knowledge prediction integrated\n",
    "              for (batch_idx, (X,y)),(batch_idx_2,(know_pred)) in zip(enumerate(train_loader), enumerate(train_knowledge_loader)): \n",
    "                    pred=model(X,y,know_pred)\n",
    "                    pred=pred[:,-horizon:,:]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss=loss_fun(pred,y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                    batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                    outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                    batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "                    \n",
    "                    tloss=loss_fun(outputs,batch_y)\n",
    "                    train_loss.append(tloss.item())\n",
    "            \n",
    "              train_loss = np.average(train_loss)\n",
    "        \n",
    "              model.eval()\n",
    "        \n",
    "              with torch.no_grad():\n",
    "          \n",
    "               for (batch_idx, (X,y)),(batch_idx_2,(know_pred)) in zip(enumerate(valid_loader), enumerate(valid_knowledge_loader)):\n",
    "                   pred=model(X,y,know_pred)\n",
    "                   pred=pred[:,-horizon:,:]\n",
    "            \n",
    "                   outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                   batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                   outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                   batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "    \n",
    "                   valid_loss=loss_fun(outputs,batch_y) \n",
    "                   valid_total_loss.append(valid_loss.item())\n",
    "            \n",
    "               valid_total_loss=np.average(valid_total_loss)          \n",
    "              print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\") \n",
    "            \n",
    "        #Just vanilla transformer    \n",
    "        elif with_knowledge==False:\n",
    "              for (batch_idx, (X,y)) in enumerate(train_loader): \n",
    "                    pred=model(X,y)\n",
    "                    pred=pred[:,-horizon:,:]\n",
    "                    optimizer.zero_grad()\n",
    "                    loss=loss_fun(pred,y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                    batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                    outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                    batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "                    \n",
    "                    tloss=loss_fun(outputs,batch_y)\n",
    "                    train_loss.append(tloss.item())\n",
    "            \n",
    "              train_loss = np.average(train_loss)\n",
    "        \n",
    "              model.eval()\n",
    "        \n",
    "              with torch.no_grad():\n",
    "          \n",
    "               for (batch_idx, (X,y)) in enumerate(valid_loader):\n",
    "                   pred=model(X,y)\n",
    "                   pred=pred[:,-horizon:,:]\n",
    "            \n",
    "                   outputs_inv = scaler.inverse_transform(pred.reshape(-1, pred.shape[-1]).detach().numpy())\n",
    "                   batch_y_inv = scaler.inverse_transform(y.reshape(-1, y.shape[-1]).detach().numpy())\n",
    "\n",
    "                   outputs = torch.tensor(outputs_inv.reshape(pred.shape))\n",
    "                   batch_y = torch.tensor(batch_y_inv.reshape(y.shape))\n",
    "    \n",
    "                   valid_loss=loss_fun(outputs,batch_y) \n",
    "                   valid_total_loss.append(valid_loss.item())\n",
    "            \n",
    "               valid_total_loss=np.average(valid_total_loss)      \n",
    "              print(f\"epoch:{epoch} train_loss:{train_loss} valid_loss:{valid_total_loss}\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75633f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "plot_dir = 'D:\\Transformer_thesis\\Plots_know_pred_normal'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8167017",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]\n",
    "ground_truth=[]\n",
    "pred_series=[]\n",
    "truth_series=[]\n",
    "loss=[]\n",
    "pred_total=[]\n",
    "y_total=[]\n",
    "enc_attention_map=[]\n",
    "dec_self_attention_map=[]\n",
    "dec_cross_attention_map=[]\n",
    "\n",
    "for i in range(X_test.size(0)):\n",
    "    if with_knowledge==True and (attention==\"auto_correlation\" or attention==\"autoformer_context_window\"):\n",
    "            current_X_test=X_test[i,:,:,:]\n",
    "            current_know_pred=Y_know_test_seq[i,:,:,:]\n",
    "            current_y_test=y_test[i,:,:,:]\n",
    "            current_X_attention=X_test_attention[i,:,:,:]\n",
    "            \n",
    "            \n",
    "            pred=model(current_X_test,current_y_test,current_know_pred,current_X_attention)\n",
    "            pred=pred[:,-horizon:,:]\n",
    "            pred=pred.reshape(-1,1).detach().numpy()\n",
    "            current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "  \n",
    "            pred_raw=scaler.inverse_transform(pred)\n",
    "            current_y_test_raw=scaler.inverse_transform(current_y_test)\n",
    "            loss.append(loss_fun(torch.tensor(pred_raw),torch.tensor(current_y_test_raw)))\n",
    "\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(current_y_test, label='Ground Truth')\n",
    "            plt.plot(pred, label='Predicted')\n",
    "            plt.title(f'Time Series {i+1}: Ground Truth vs Predicted Values')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            #plt.show()\n",
    "            plt.savefig(os.path.join(plot_dir, f'Time_Series_{i+1}_plot.png'))\n",
    "            plt.close()\n",
    "    elif with_knowledge==True and attention!=\"auto_correlation\":\n",
    "            current_X_test=X_test[i,:,:,:]\n",
    "            current_know_pred=Y_know_test_seq[i,:,:,:]\n",
    "            current_y_test=y_test[i,:,:,:]\n",
    "            \n",
    "            pred=model(current_X_test,current_y_test,current_know_pred)\n",
    "            pred=pred[:,-horizon:,:]\n",
    "            pred=pred.reshape(-1,1).detach().numpy()\n",
    "            current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "  \n",
    "            pred_raw=scaler.inverse_transform(pred)\n",
    "            current_y_test_raw=scaler.inverse_transform(current_y_test)\n",
    "            loss.append(loss_fun(torch.tensor(pred_raw),torch.tensor(current_y_test_raw)))\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(current_y_test, label='Ground Truth')\n",
    "            plt.plot(pred, label='Predicted')\n",
    "            plt.title(f'Time Series {i+1}: Ground Truth vs Predicted Values')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            #plt.show()\n",
    "            plt.savefig(os.path.join(plot_dir, f'Time_Series_{i+1}_plot.png'))\n",
    "            plt.close()\n",
    "    elif with_knowledge==False:\n",
    "            current_X_test=X_test[i,:,:,:]\n",
    "            current_y_test=y_test[i,:,:,:]\n",
    "            \n",
    "            pred=model(current_X_test,current_y_test)\n",
    "            pred=pred[:,-horizon:,:]\n",
    "            pred=pred.reshape(-1,1).detach().numpy()\n",
    "            current_y_test=current_y_test.reshape(-1,1).detach().numpy()\n",
    "  \n",
    "            pred_raw=scaler.inverse_transform(pred)\n",
    "            current_y_test_raw=scaler.inverse_transform(current_y_test)\n",
    "            loss.append(loss_fun(torch.tensor(pred_raw),torch.tensor(current_y_test_raw)))\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(current_y_test, label='Ground Truth')\n",
    "            plt.plot(pred, label='Predicted')\n",
    "            plt.title(f'Time Series {i+1}: Ground Truth vs Predicted Values')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            #plt.show()\n",
    "            plt.savefig(os.path.join(plot_dir, f'Time_Series_{i+1}_plot.png'))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79a98e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.7035),\n",
       " tensor(1.4615),\n",
       " tensor(0.0898),\n",
       " tensor(0.0984),\n",
       " tensor(0.1287)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "521ddc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6964)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val=torch.stack(loss,dim=0)\n",
    "mean_loss=torch.mean(loss_val)\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f70105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss, label=\"Loss\")\n",
    "\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abddb211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
